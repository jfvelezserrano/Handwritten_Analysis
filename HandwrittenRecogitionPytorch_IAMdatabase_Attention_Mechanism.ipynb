{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antes de empezar\n",
    "\n",
    "conda activate python3.6_cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "#import skimage\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Ignore harmless warnings:\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n",
      "3.6.10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TITAN X (Pascal)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "print(torch.__version__)\n",
    "print(platform.python_version())\n",
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['X_trn', 'X_tst', 'X_val', 'filename_trn', 'filename_tst', 'filename_val', 'image_length_trn', 'image_length_tst', 'image_length_val', 'target_dict_keys', 'target_dict_values', 'target_length_trn', 'target_length_tst', 'target_length_val', 'target_trn', 'target_tst', 'target_val']>\n"
     ]
    }
   ],
   "source": [
    "# Loading preprocessed images\n",
    "\n",
    "import h5py\n",
    "filename = \"/home/abarreiro/data/handwriting/seq2seq/IAM_words_48_192.hdf5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    data_header = list(f.keys())\n",
    "    data = []\n",
    "    \n",
    "    for item in data_header:\n",
    "        \n",
    "        # Getting data:\n",
    "        data.append(list(f[item]))\n",
    "        \n",
    "    # Creating dictionary between data names and data   \n",
    "    new_dict = {name: obj for name, obj in zip(data_header, data)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.  26.  58.  53. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n",
      " 100. 100. 100. 100. 100.]\n"
     ]
    }
   ],
   "source": [
    "print(new_dict['target_trn'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47926\n",
      "(48, 192)\n",
      "b'!'\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(new_dict['X_trn']))\n",
    "print(new_dict['X_trn'][1].shape)\n",
    "print(new_dict['target_dict_values'][1])\n",
    "print(max(new_dict['target_length_trn'] + new_dict['target_length_val'] + new_dict['target_length_tst']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo diccionario, codificación y longitud máxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary used in seq2seq paper\n",
    "decoder_dict = {0: '0', 1: '!', 2: 'L', 3: 'z', 4: 'G', 5: 'm', 6: '6', 7: '/', 8: 'j', 9: 's', 10: 'S', 11: '5',\n",
    "                12: 'R', 13: ')', 14: 'u', 15: 'y', 16: '9', 17: 'g', 18: '3', 19: '1', 20: 'e', 21: \"'\", 22: ':',\n",
    "                23: 'Q', 24: '2', 25: 'a', 26: 't', 27: 'A', 28: '7', 29: ';', 30: 'i', 31: 'H', 32: 'W', 33: ',',\n",
    "                34: '(', 35: 'O', 36: 'U', 37: 'K', 38: 'd', 39: '*', 40: '.', 41: '?', 42: 'q', 43: '-', 44: 'r',\n",
    "                45: 'n', 46: '&', 47: 'C', 48: '\"', 49: 'h', 50: 'v', 51: 'f', 52: 'E', 53: 'p', 54: 'x', 55: '+',\n",
    "                56: 'w', 57: 'b', 58: 'o', 59: ' ', 60: 'B', 61: 'P', 62: 'D', 63: 'I', 64: 'J', 65: 'V', 66: 'N',\n",
    "                67: 'M', 68: '8', 69: 'k', 70: 'c', 71: '4', 72: 'T', 73: 'X', 74: 'l', 75: 'Z', 76: 'F', 77: 'Y',\n",
    "                78: 'START', 79: 'END', 100: 'PAD'}\n",
    "\n",
    "inverse_decoder_dict = {v: k for k, v in decoder_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(inverse_decoder_dict['END'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One_hot_mapping assigns to each number in decoder_dict its corresponding one-hot vector:\n",
    "\n",
    "one_hot_mapping = {}\n",
    "\n",
    "cont = 0\n",
    "for item in decoder_dict:\n",
    "    vector = torch.zeros(1, 1, len(decoder_dict))\n",
    "    vector[0, 0, cont] = 1.0\n",
    "    one_hot_mapping[item] = vector\n",
    "    cont += 1\n",
    "\n",
    "# Inverse_one_hot_mapping assigns to each one-hot vector its corresponding number in decoder_dict\n",
    "inverse_one_hot_mapping = {v: k for k, v in one_hot_mapping.items()}\n",
    "\n",
    "# One_hot_to_char assigns to each possible one-hot vector its corresponding character from decoder_dict\n",
    "one_hot_to_char = {}\n",
    "\n",
    "for one_hot, char in zip(inverse_one_hot_mapping, inverse_decoder_dict):\n",
    "    \n",
    "    one_hot_to_char[one_hot] = char   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]])\n",
      "PAD\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_mapping[100])\n",
    "print(one_hot_to_char[one_hot_mapping[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1d8dcd6128>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(new_dict['X_trn'][1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\n"
     ]
    }
   ],
   "source": [
    "# All word vectors in 'target' are adjusted to max_length = 19:\n",
    "a = [len(word) for word in new_dict['target_trn']]\n",
    "print(np.unique(a))\n",
    "\n",
    "MAX_LENGTH = np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n",
      " 100. 100. 100. 100. 100.]\n",
      "tensor([ 27., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
      "        100., 100., 100., 100., 100., 100., 100.], dtype=torch.float64)\n",
      "[ 25.   9.   9.  14.  44.  20.  38.  45.  20.   9.   9. 100. 100. 100.\n",
      " 100. 100. 100. 100. 100.]\n",
      "tensor([ 25.,   9.,   9.,  14.,  44.,  20.,  38.,  45.,  20.,   9.,   9., 100.,\n",
      "        100., 100., 100., 100., 100., 100., 100.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def numpy_to_torch(array_list):\n",
    "    tensor_list = []\n",
    "    for array in array_list:\n",
    "        tensor_list.append(torch.from_numpy(array))\n",
    "        \n",
    "    return tensor_list\n",
    "    \n",
    "a = numpy_to_torch(new_dict['target_trn'])\n",
    "print(new_dict['target_trn'][0])\n",
    "print(a[0])\n",
    "\n",
    "X_trn = numpy_to_torch(new_dict['X_trn'])\n",
    "X_val = numpy_to_torch(new_dict['X_val'])\n",
    "X_tst = numpy_to_torch(new_dict['X_tst'])\n",
    "target_trn = numpy_to_torch(new_dict['target_trn'])\n",
    "target_val = numpy_to_torch(new_dict['target_val'])\n",
    "target_tst = numpy_to_torch(new_dict['target_tst'])\n",
    "\n",
    "print(new_dict['target_tst'][0])\n",
    "print(target_tst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[ 27. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n",
      " 100. 100. 100. 100. 100.]\n",
      "1\n",
      "[ 67.  35.  65.  52. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n",
      " 100. 100. 100. 100. 100.]\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = new_dict['target_trn'][0:2]\n",
    "\n",
    "for j,word in enumerate(a):\n",
    "    print(j)\n",
    "    print(word)\n",
    "        \n",
    "print(type(new_dict['target_trn']))\n",
    "\n",
    "b = []\n",
    "for item in new_dict['target_trn']:\n",
    "    b.append(torch.from_numpy(item))\n",
    "    \n",
    "print(type(b[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generando patches y etiquetas para muestra finita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_imagen(word, height, width):\n",
    "    \n",
    "    image = np.zeros(shape = (height, width), dtype = np.uint8)\n",
    "    image = cv2.putText(image, text = word, org = (5, 30), \n",
    "                        fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.62, color = (255, 255, 255), \n",
    "                        thickness = 1, lineType = cv2.LINE_AA)  \n",
    "    # image = skimage.util.random_noise(image, mode='s&p') # just in case we wanted to add some noise\n",
    "    return image\n",
    "\n",
    "\n",
    "def patch_gen(word, color_channels, height, width, patch_height, patch_width, stepsize):\n",
    "    \n",
    "    image = crear_imagen(word, height, width)\n",
    "    image = torch.from_numpy(image)\n",
    "    image = image / 255\n",
    "        \n",
    "    n_patches = int((width - patch_width)/stepsize + 1)\n",
    "    patches_tensor = torch.empty(n_patches, color_channels, patch_height, patch_width)    \n",
    "    \n",
    "    start = 0\n",
    "    \n",
    "    for p in range(n_patches):\n",
    "        \n",
    "        patches_tensor[p, 0, :, :] = image[:, start:start + patch_width] # sliding window\n",
    "        start += stepsize # updating the bottom-left position of the patch adding the stepsize\n",
    " \n",
    "    return patches_tensor\n",
    "\n",
    "\n",
    "def complete_set(word_set, color_channels, height, width, patch_height, patch_width, stepsize):\n",
    "    \n",
    "    complete_set = []\n",
    "    \n",
    "    for word in word_set: \n",
    "        \n",
    "        word_tensor = patch_gen(word, color_channels, height, width, patch_height, patch_width, stepsize)\n",
    "        complete_set.append((word_tensor, word))\n",
    "        \n",
    "    return complete_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generando patches y etiquetas para muestra infinita aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_imagen2(word, height, width):\n",
    "    \n",
    "    image = np.zeros(shape = (height, width), dtype = np.uint8)\n",
    "    cv2.putText(image, text = word, org = (5, 30),\n",
    "        fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.62, color = (255, 255, 255),\n",
    "        thickness = 1, lineType = cv2.LINE_AA)  \n",
    "    # image = skimage.util.random_noise(image, mode='s&p') # just in case we wanted to add some noise\n",
    "    return image\n",
    "\n",
    "\n",
    "def patch_gen2(batch_element, word, color_channels, height, width, n_patches, \n",
    "               patch_height, patch_width, stepsize, patches_tensor):\n",
    "    \n",
    "    image = crear_imagen2(word, height, width)\n",
    "    image = torch.from_numpy(image)\n",
    "    image = image / 255\n",
    "        \n",
    "    start = 0\n",
    "    \n",
    "    for p in range(n_patches):\n",
    "        \n",
    "        patches_tensor[batch_element, p, 0, :, :] = image[:, start:start + patch_width] # sliding window\n",
    "        start += stepsize # updating the bottom-left position of the patch adding the stepsize\n",
    " \n",
    "    return patches_tensor\n",
    "\n",
    "def complete_set2(word_set, batch_size, color_channels, height, width, patch_height, patch_width, stepsize):\n",
    "    \n",
    "    n_patches = int((width - patch_width)/stepsize + 1)\n",
    "    \n",
    "    patches_tensor = torch.empty(batch_size, n_patches, color_channels, patch_height, patch_width)\n",
    "    word_list = []\n",
    "    \n",
    "    for batch_element, word in enumerate(word_set):\n",
    "        \n",
    "        patches_tensor = patch_gen2(batch_element, word, color_channels, height, width, n_patches, \n",
    "                                    patch_height, patch_width, stepsize, patches_tensor)\n",
    "        word_list.append(word)\n",
    "\n",
    "    return patches_tensor, word_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_train_set = complete_set(train_set, color_channels = 1, height = 48, width = 192,\n",
    "                              patch_height = 48, patch_width = 10, stepsize = 2)\n",
    " \n",
    "comp_val_set = complete_set(val_set, color_channels = 1, height = 48, width = 192,\n",
    "                            patch_height = 48, patch_width = 10, stepsize = 2)\n",
    "\n",
    "comp_test_set = complete_set(test_set, color_channels = 1, height = 48, width = 192, \n",
    "                             patch_height = 48, patch_width = 10, stepsize = 2)\n",
    "\n",
    "comp_test_set_2 = complete_set(test_set_2, color_channels = 1, height = 48, width = 192,\n",
    "                               patch_height = 48, patch_width = 10, stepsize = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 92, 1, 48, 10])\n",
      "torch.Size([1472, 1, 48, 10])\n",
      "talkin\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIIAAAD6CAYAAABtcp9RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN2UlEQVR4nO2dfaxlV1nGf0/nowPD1FKnNmMLAqbWRAOIozVUIgUL06JWjUQ6ykcDmdSAKcbEVk00Rv8ogSgxiDBgQwlfNtDCWAtlOlIrKYXOwHSmZWhpWijTmTj2C9uqnXvPff1jr3PnnHvnnr3OPfuus+85zy/ZmbP33Xftlclz3/Wud63zbEUExpwy7g6YdmAhGMBCMAkLwQAWgklYCAYYUQiStkm6T9IDkq5uqlOmPFpuHUHSGuB+4CLgMHAXcFlEfHup31mvU2MDG5f1vHHxfzzD8XhWo7Tx+gs3xmOPd7Lu3Xfg2VsiYtsoz1sOa0f43V8EHoiIBwEkfQa4FFhSCBvYyPl67QiPLM/XY8/IbTz2eIdv3PLCrHvXbPnu5pEfuAxGEcLZwA96zg8D54/WnckkgDnmxt2NgYwihJOFy0XjjKQdwA6ADTx3hMetXoJgJvKGhnExihAOAy/oOT8HOLLwpojYCewEOE1nTO3CxiRHhLuAcyW9GHgEeBOwvZFeTRhB0Gn54t6yhRARs5LeBdwCrAGujYh7G+vZhDG3eNRsFaNEBCLiZuDmhvoysQTQmWQhmHwmOiKYPAKYmdQcweQThIcGAwR02q0DC6EEVWWx3VgIRRCdkxZi24OFUIAqWbQQpp6qjmAhGGDOEcE4IhgAAtFp+fZQC6EQHhoMgTgea8bdjYFYCAWoCkoeGgxOFg0QITrhiGCAOUcEUyWL7f6vbnfvJgQni2aejusIxpVFM8+cZw2mWnSyEKaeQMy4xGwicEHJAMgFJZNyBEcEA04WDVWy2PaNKe2W6YRQbWdfm3XUUedkJ+lHJP2LpLsl3Svp8pw+OiIUoZkvuCQnu3+gx8lO0q4FTnbvBL4dEb8u6UzgPkmfjIjjg9q2EAoQNFZZzHGyC2CTJAHPAx4HZusathAKMURE2Cxpb8/5zuRDBXlOdh8AdlH5WW0Cfjciar96aSEUIELDRIRHI2LrEj/LcbJ7PbAfeA3wk8BuSf8REf896KFOFgtQJYtrso4acpzsLgduiIoHgIeAn65r2EIoQrVnMeeoYd7JTtJ6Kie7XQvueRh4LYCks4DzgAfrGq59sqRrJR2TdE/PtTMk7Zb03fTv8+vamWaqZFFZx8B2ImaBrpPdIeD6iLhX0hWSrki3/TXwSkkHgT3AVRHxaF0fc3KEj1ElIB/vuXY1sCcirklz2auBqzLamlqaqiyezMkuIj7U8/kI8Lph263tXUTcTjUF6eVS4Lr0+TrgN4d98DTRrSyOGhFWkuXOGs6KiKMAEXFU0o812KeJZOo3r9qUu9qPMDM3mUL4T0lbUjTYAhxb6kabcneHhnYLYbm92wW8NX1+K/CFZrozuXTSekPdMS5qI4KkTwOvpip9Hgb+ErgGuF7S26nmrW9cyU6udrrTxzZTK4SIuGyJH62ud/KMlfYPDV5rKIT3LJo0a/B29qlnNWxVsxAK4aHBTMaswTSDZw2GCDFrIRjw0GBwjmB6sBCM6wjmBK4jGCJgdkI3ppgh8dBgnCOYE4SFYMDJoqFKFj00GEB0PGsw4Byh/ZyyYAvZXKfxR3itwVRElSe0GQuhEJ41mOp9DU4W28Pac85edO2+9/R/kfslH1jgO3X3HY0820ODATxrMFTRwEIwQPunj+3OYCaIiLyjjjov5nTPqyXtT17M/57Tv6mKCJ0zT1907Z9f+eG+8ytuvbL/d+4b/W8lEHMNzBpyvJglnQ58ENgWEQ/n2ho5IhQiMo8a5r2Yk8l214u5l+1UhpsPA0TEkm42vVgIJUjJYs5Rw8m8mBfOiX8KeL6k2yTtk/SWnC5O1dAwVvLrCINMuXO8mNcCP09lZPIc4GuS7oyI+wc91EIoxBDTx0Gm3DlezIdTG88Az0i6HXgZMFAIHhoKEMDcnLKOGnK8mL8AvErSWknPpbLxP1TXsCNCCQJooI4QEbOSul7Ma4Bru17M6ecfiohDkr4EHADmgI9GxD1Lt1phIRSiqbWGOi/mdP5e4L3DtJvjzv4CSV+RdCgVKK5M1+3QPgwNzR9XipyIMAv8cUR8U9ImYJ+k3cDbaLlD+ykbNvSdz562ftE969S/2ji7sT+EN/NK56yp4VjJcWc/GhHfTJ+foko8zsYO7cMxARFhHkkvAn4O+DqZDu025aYqKNXPCMZK9vRR0vOAzwHvrntRVC8RsTMitkbE1nWcupw+TgjKPMZDVkSQtI5KBJ+MiBvS5WyH9nHxg3e/ou98+/Y9i+556fr+POJ9f9S/CPXOr/xXM51p+Q6lnFmDgH8CDkXE3/b8yA7twzABOcIFwJuBg5L2p2t/hh3a82mooLSS5Lizf5WlBy87tGfizaumouWzhokWwuaDM33nH9n7qkX3/MFF3+o7/5sH+19PcfT4JxrpixwRzLgTwRwshCJo9SeLpiEcEcbHqf96V9/5eUd+ZtE9D17Y/1/w9Kd+vO987rF1zXRmrv6WcTLRQmgNk1BHMM3gWYOpaLkQvHnVAI4IxfDQYNJ+dieLBlqfI1gIhfDQYCosBANYCKYaFjw0mArPGgw4IpguFoLBOYKZx0IwAGr5xhSvPhpgyiJCZ+PibWffOb6l73zd//bH8MbGdg8NxsmiOUHLheAcoRQNfRs6x5Q73fcLkjqSfiene1MVEdY/8sSia091+v0Rnjy3/29j9rbRnyuamTXkmHL33PceKhu+LBwRShAnFp7qjhpyTLkB/pDK2CTbvMRCKEX+0LBZ0t6eY0dPK7Wm3JLOBn4L6PNerGOqhoaxkp8sDvJizjHlfj9wVUR0KrObPCyEQjQ0fcwx5d4KfCaJYDNwiaTZiPj8oIanSgizD31/0bX37b+o7/xdb+pzt+XvPvfDZh7ejBDmTbmBR6hMubf3PSbixd3Pkj4G3FQnApgyIYyNaGbWkGPKvdy2LYRSFDTl7rn+ttx2c+z1Nkj6hqS7kyn3X6XrNuUegoamjytGTkR4FnhNRDydjDe/KumLwG/TclPuHM778/4i0+c//PK+8yePH2zmQau9xBwVT6fTdekIbMqdT24NYYxiySooSVqTzDaPAbsjYpEpN5D1fsFpREzG0EBEdICXp5dL3ijpZ3MfYHf2irYvQw9VYo6IJ4HbgG0kU26AQabcdmdPtHxoqI0Iks4EZiLiSUnPAX6VamWra8p9DavYlHthkWnDG/rf8qKZftPOZdPyiJAzNGwBrktLm6cA10fETZK+hk2585iEHUoRcYDqrS0Lrz+GTbnzWe1CMM3Q9u3sFsICYub4ggvN/Cmv+qHBNIBNuc08FoLpVhbbjIVQCM21WwkWQgmcI5guHhpMhYVgwBHBdLEQTFO7mFcSC6EAriOYE7T8ncAWQiEcEYwLSuYEThYNYCEYSENDu8cGC6EQThZNhYVgXFAyFRHemGIS7daBhVAKDw0mvRK43Uqw4WYpCnkxS/o9SQfScYekl+V0zxGhEE0MDZlezA8BvxIRT0i6GNgJnF/XtoVQiIZmDfNezACSul7M80KIiDt67r+TypSzFg8NJRjOQ2kkL+YFvB34Yk4XHREKUBWUsiPCqF7M1Y3ShVRC+OWch1oIpWhm9THHixlJLwU+ClycfCxq8dBQCEVkHTXMezFLWk/lxbyr7znSC4EbgDdHxP25/XNEKEFDO5QyvZj/AvhR4IPJoX12wFAzj4VQhObWGuq8mCPiHcA7hm3XQihFyzemZOcIyX31W5JuSuc25c4lfcEl5xgXwySLVwKHes6vpjLlPhfYk87NUkTkHWMi14v5HOANVFOSLjblHobV7ryaeD/wJ8Cmnmt9ptySbMo9AM21extzzos7fg04FhH7lvMASTu65dIZnl1OE6ufoCoo5RxjIiciXAD8hqRLgA3AaZI+QTLlTtFgoCk31QoYp+mMdqfOK4TIKhaNlZwXd/xpRJwTES+iqmT9W0T8PidMuWEVm3IXo+XJ4ih1hGuwKXc+LY8IQwkhIm6jel+DTbmHoZsjtBhXFgvR9lmDhVCE8Y7/OVgIJfCXYM087R4ZLIRStL2OYCGUwkIwRECn3WODhVAKRwQDWAiGVfElWAuhCAHhHMEEThZNwjmCASwEA150MhUBeBnaAI4IBsAlZgMpRbAQDLiyaBLOEQwRnjWYhCOCgSA6nXF3YiAWQglWwTK0XdVKEXN5Rw0ZXsyS9Pfp5wckvSKne44IBQggGogImV7MFwPnpuN84B/J8GJ2RChBRFMRYd6LOSKOA10v5l4uBT4eFXcCpyfbgoE4IhSioWTxZF7MC//al/JrPjqo4aJCeIonHr01Pvt9YDPw6Ao9pum2f2LUBp7iiVtujc9uzrx9g6S9Pec7k9kI5HkxZ/s191JUCBFxJoCkvTluoMthJdteLhGxraGmcryYs/yaF+IcYXVR68Wczt+SZg+/BPywa3o2COcIq4hML+abgUuAB4D/AS7PaVsxhtKnpB09496qaXuSGYsQTPtwjmCAMQihrkQ6Qrvfk3RQ0v4F0y+TQdGhIZVI76enRApctqBEuty2vwdsjYiVqk9MNKUjQk6J1IyB0kIY9nV1wxDAlyXtW/CKPJNB6TrCssqfmVwQEUeSS/xuSd+JiNsbanviKR0RllX+zCEijqR/jwE3Ug1DJpPSQsgpkQ6NpI2SNnU/A68D7hm13Wmi9KLTSUukDTR9FnBjer3dWuBTEfGlBtqdGlxZNIAriyZhIRjAQjAJC8EAFoJJWAgGsBBMwkIwAPw/EXI6MieMeSsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "train_loader = DataLoader(comp_train_set, batch_size = 16, shuffle = True, drop_last= True)\n",
    "val_loader = DataLoader(comp_val_set, batch_size = 16, shuffle = False, drop_last= True)\n",
    "test_loader = DataLoader(comp_test_set, batch_size = 16, shuffle = False, drop_last= True)\n",
    "test_2_loader = DataLoader(comp_test_set_2, batch_size = 16, shuffle = False, drop_last= True)\n",
    "\n",
    "for image, label in train_loader:\n",
    "    break\n",
    "    \n",
    "#print(image)    \n",
    "image_cnn = image.view(-1, 1, 48, 10)   \n",
    "print(image.shape)\n",
    "print(image_cnn.shape)\n",
    "print(label[3])\n",
    "\n",
    "for n_patch in range(0,10):\n",
    "    patch = image[3,n_patch,0,:,:].cpu()\n",
    "    plt.imshow(patch)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_target(labels, seq_len, output_size, batch_size):    \n",
    "    one_hot_target = torch.empty(batch_size, seq_len, output_size) \n",
    "\n",
    "    for j,word in enumerate(labels):\n",
    "        length = len(word)\n",
    "        one_hot_target[j, 0, :] = mapeo['START']\n",
    "\n",
    "        for k,letter in enumerate(word):\n",
    "            one_hot_target[j, k + 1, :] = mapeo[letter]\n",
    "\n",
    "        one_hot_target[j, length + 1, :] = mapeo['END']\n",
    "        one_hot_target[j, length + 2: seq_len, :] = mapeo['PAD']\n",
    "        \n",
    "    return one_hot_target        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_one_hot_target_IAM(labels, seq_len, output_size, batch_size):\n",
    "    # labels: tensor containing the labels of the words in the batch\n",
    "    # each word label consists of a vector of length 19 (MAX LENGTH). The 19 elements are the encoded characters of the word\n",
    "    # (according to Jorge's decoder dict, and completed with PADs to reach length = 19)\n",
    "    one_hot_target = torch.empty(batch_size, seq_len, output_size) # future one-hot encoding tensor for the words of the batch\n",
    "    START = inverse_decoder_dict['START'] # code number of the START token (according to Jorge's decoder_dict)\n",
    "    END = inverse_decoder_dict['END']\n",
    "    PAD = inverse_decoder_dict['PAD']\n",
    "    \n",
    "    for j, word in enumerate(labels):\n",
    "        \n",
    "        It_has_PADs = torch.any(word == PAD).item() # (majority case: the label vector of the word is completed with PADs)\n",
    "        one_hot_target[j, 0, :] = one_hot_mapping[START] # START token's one-hot vector goes first\n",
    "        \n",
    "        for k, letter in enumerate(word):\n",
    "            one_hot_target[j, k + 1, :] = one_hot_mapping[letter] # one-hot encoding of the rest of letters (including PADs)\n",
    "            \n",
    "        one_hot_target[j, -1, :] = one_hot_mapping[END] # last = END token\n",
    "        \n",
    "        if It_has_PADs == True: # if we had PADs\n",
    "            \n",
    "            array_of_PADs = torch.where(word == PAD)[0] \n",
    "            first_PAD = torch.min(array_of_PADs).item() # we store the first position where it appeared\n",
    "            first_PAD = first_PAD + 1 # (recall that we added the START as first element, so the indices won't match)\n",
    "            one_hot_target[j, first_PAD, :] = one_hot_mapping[END] # we replace that first PAD by an END\n",
    "            one_hot_target[j, -1, :] = one_hot_mapping[PAD] # then the last element was a PAD, and not the END token\n",
    "            \n",
    "    return one_hot_target\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "tensor([11, 12, 13, 14, 15, 16, 17, 18])\n"
     ]
    }
   ],
   "source": [
    "a = torch.empty(2, 21, len(decoder_dict))\n",
    "a[0, 0, :] = one_hot_mapping[78]\n",
    "a[1, 0, :] = one_hot_mapping[78]\n",
    "a[0, 1:21, :] = one_hot_mapping[0]\n",
    "a[1, 1:21, :] = one_hot_mapping[1]\n",
    "\n",
    "print(torch.min(torch.where(target_tst[0]==inverse_decoder_dict['PAD'])[0]).item())\n",
    "print(torch.where(target_tst[0]==100.)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "78\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "print(torch.any(target_tst[0]==inverse_decoder_dict['PAD']).item())\n",
    "#print(target_tst[0])\n",
    "print(inverse_decoder_dict['START'])\n",
    "START = inverse_decoder_dict['START']\n",
    "print(one_hot_mapping[START])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((one_hot_mapping[0], one_hot_mapping[START]), dim=1)\n",
    "#torch.cat((one_hot_mapping[START], one_hot_mapping[0]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18])\n",
      "tensor([ 67.,  35.,  65.,  52., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
      "        100., 100., 100., 100., 100., 100., 100.], dtype=torch.float64)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "PAD = inverse_decoder_dict['PAD']\n",
    "word = target_trn[1]\n",
    "print(torch.any(word == PAD).item())\n",
    "print(torch.where(word==PAD)[0])\n",
    "print(word)\n",
    "array_of_PADs = torch.where(word==PAD)[0]\n",
    "first_PAD = torch.min(array_of_PADs).item()\n",
    "print(first_PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_conversion(decoder_output, output_size):\n",
    "    \n",
    "    one_hot_output_letter = torch.zeros(1, 1, output_size)\n",
    "    index = torch.argmax(decoder_output, dim = 2).item()\n",
    "    one_hot_output_letter[0, 0, index] = 1.\n",
    "    \n",
    "    return one_hot_output_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definiendo la arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, IN_CHANNELS, FILTERS_CNN_1, NEURONS_IN_DENSE_LAYER,\n",
    "                 PATCH_HEIGHT, PATCH_WIDTH, STRIDE, PADDING, KERNEL_SIZE):\n",
    "        super().__init__()\n",
    "        self.IN_CHANNELS = IN_CHANNELS\n",
    "        self.FILTERS_CNN_1 = FILTERS_CNN_1\n",
    "        self.NEURONS_IN_DENSE_LAYER = NEURONS_IN_DENSE_LAYER\n",
    "        self.PATCH_HEIGHT_AFTER_POOLING = PATCH_HEIGHT//2\n",
    "        self.PATCH_WIDTH_AFTER_POOLING = PATCH_WIDTH//2\n",
    "        self.STRIDE = STRIDE\n",
    "        self.PADDING = PADDING\n",
    "        self.KERNEL_SIZE = KERNEL_SIZE\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = self.IN_CHANNELS, out_channels = self.FILTERS_CNN_1,\n",
    "                               kernel_size = self.KERNEL_SIZE, stride = self.STRIDE, padding = self.PADDING)\n",
    "        self.fc1 = nn.Linear(self.PATCH_HEIGHT_AFTER_POOLING * self.PATCH_WIDTH_AFTER_POOLING * self.FILTERS_CNN_1, \n",
    "                             self.NEURONS_IN_DENSE_LAYER)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu((self.conv1(X)))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, self.PATCH_HEIGHT_AFTER_POOLING*self.PATCH_WIDTH_AFTER_POOLING*self.FILTERS_CNN_1)\n",
    "        X = self.fc1(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, encoder_seq_len):        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = encoder_seq_len\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, batch_first = True)\n",
    "\n",
    "    def forward(self, input, hidden):        \n",
    "        output = input.view(self.batch_size, self.seq_len, self.input_size)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, self.batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(1, self.batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, batch_size, decoder_seq_len):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = decoder_seq_len\n",
    "\n",
    "        self.lstm = nn.LSTM(self.output_size, self.hidden_size, batch_first = True)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 2)\n",
    "        # dim = 2 porque esta última dimensión es la correspondiente a output_size, que es sobre\n",
    "        # la que queremos hacer el softmax\n",
    "\n",
    "    def forward(self, input, hidden):        \n",
    "        output = input.view(self.batch_size, self.seq_len, self.output_size)\n",
    "        #output = F.relu(output) # la relu se metía aquí porque en el\n",
    "        #caso NLP del ejemplo de PyTorch previamente había una capa de embedding\n",
    "        #No nos hace falta porque nuestro tensor de inputs ya es one-hot\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, self.batch_size, self.hidden_size, device=device),\n",
    "               torch.zeros(1, self.batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p, batch_size, encoder_seq_len, decoder_seq_len):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_seq_len = encoder_seq_len\n",
    "        self.decoder_seq_len = decoder_seq_len\n",
    "        \n",
    "        self.attn = nn.Linear(self.output_size + self.hidden_size, self.encoder_seq_len)\n",
    "        self.attn_combine = nn.Linear(self.output_size + self.hidden_size, self.output_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.lstm = nn.LSTM(self.output_size, self.hidden_size, batch_first = True)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden, encoder_outputs):\n",
    "        \n",
    "        inputs = inputs.view(self.batch_size, self.decoder_seq_len, self.output_size)\n",
    "        inputs = self.dropout(inputs)\n",
    "        \n",
    "        decoder_hidden_states = hidden[0].view(self.batch_size, self.decoder_seq_len, self.hidden_size) #[0] -- hidden, not cell\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((inputs, decoder_hidden_states), 2)), dim = 2)\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs)\n",
    "\n",
    "        output = torch.cat((inputs, attn_applied), 2)\n",
    "        output = self.attn_combine(output)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output), dim = 2)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, self.batch_size, self.hidden_size, device=device),\n",
    "               torch.zeros(1, self.batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauDecoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, batch_size, n_patches, MAX_LENGTH, n_layers, drop_prob):\n",
    "        super(BahdanauDecoder, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.enc_seq_len = n_patches\n",
    "        self.dec_seq_len = MAX_LENGTH + 2\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        #self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(self.batch_size, self.hidden_size, self.dec_seq_len))\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        self.lstm = nn.LSTM(self.output_size + self.hidden_size, self.hidden_size, batch_first=True)\n",
    "        self.classifier = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden, encoder_outputs):\n",
    "        #encoder_outputs = encoder_outputs.squeeze()\n",
    "        # Embed input words\n",
    "        #embedded = self.embedding(inputs).view(1, -1)\n",
    "        inputs = self.dropout(inputs)\n",
    "        output = inputs.view(self.batch_size, self.dec_seq_len, self.output_size)\n",
    "\n",
    "        # Calculating Alignment Scores\n",
    "        hidden_state = hidden[0].view(self.batch_size, n_layers, self.hidden_size) # hidden[0] --> picking h. state and not cell\n",
    "        x = torch.tanh(self.fc_hidden(hidden_state) + self.fc_encoder(encoder_outputs)) # shape: [batch, seq_len, hidden_size]\n",
    "        #alignment_scores = x.bmm(self.weight.unsqueeze(2))  \n",
    "        alignment_scores = torch.bmm(x, self.weight) # shape: [batch, enc_seq, dec_seq]\n",
    "        \n",
    "        # Softmaxing alignment scores to get Attention weights\n",
    "        #attn_weights = F.softmax(alignment_scores.view(1,-1), dim=1)\n",
    "        \n",
    "        attn_weights = F.softmax(alignment_scores, dim = 1)\n",
    "\n",
    "        # Multiplying the Attention weights with encoder outputs to get the context vector\n",
    "        #context_vector = torch.bmm(attn_weights.unsqueeze(0),\n",
    "        #                         encoder_outputs.unsqueeze(0))\n",
    "        context_vector = torch.bmm(attn_weights.view(self.batch_size, self.dec_seq_len, self.enc_seq_len), \n",
    "                                   encoder_outputs)\n",
    "        \n",
    "        \n",
    "        # Concatenating context vector with embedded input word\n",
    "        #output = torch.cat((embedded, context_vector[0]), 1).unsqueeze(0)\n",
    "        \n",
    "        output = torch.cat((output, context_vector), dim=2)\n",
    "        \n",
    "        # Passing the concatenated vector as input to the LSTM cell\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        # Passing the LSTM output through a Linear layer acting as a classifier\n",
    "        #output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
    "        \n",
    "        output = F.log_softmax(self.classifier(output), dim = 2)\n",
    "        \n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "CNN_model = ConvolutionalNetwork(IN_CHANNELS = 1, FILTERS_CNN_1 = 4, NEURONS_IN_DENSE_LAYER = 1024, \n",
    "                                 PATCH_HEIGHT = 48, PATCH_WIDTH = 10, STRIDE = 1, PADDING = 0, KERNEL_SIZE = 1).cuda(1)\n",
    "CNN_optimizer = torch.optim.Adam(CNN_model.parameters())\n",
    "\n",
    "Encoder_model = EncoderRNN(input_size = 1024, hidden_size = 256, batch_size = 16, encoder_seq_len = 92).cuda(1)\n",
    "Encoder_optimizer = optim.SGD(Encoder_model.parameters(), lr = 0.001)\n",
    "\n",
    "Decoder_model = AttnDecoderRNN(output_size = len(letters), hidden_size = 256, dropout_p = 0.1, batch_size = 16,\n",
    "                               encoder_seq_len = 92, decoder_seq_len = 1).cuda(1)\n",
    "Decoder_optimizer = optim.SGD(Decoder_model.parameters(), lr = 0.001)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(decoder_output, ground_truth, batch_size):\n",
    "    loss = 0\n",
    "        \n",
    "    for j in range(batch_size):\n",
    "        loss += criterion(decoder_output[j], ground_truth[j])               \n",
    "    \n",
    "    loss = loss/batch_size\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    train_losses = []\n",
    "    for num_batch, (image, labels) in enumerate(train_loader):        \n",
    "        num_batch += 1\n",
    "        encoder_hidden = Encoder_model.initHidden()\n",
    "\n",
    "        image_cnn = image.view(-1, 1, 48, 10).cuda(1)\n",
    "        encoder_input = CNN_model(image_cnn)\n",
    "        encoder_outputs, encoder_hidden = Encoder_model(encoder_input, encoder_hidden)\n",
    "        \n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = get_one_hot_target(labels=labels, seq_len = MAX_LENGTH + 2, output_size = 29, batch_size = 16).cuda(1)\n",
    "        \n",
    "        \n",
    "        for num_letter in range(MAX_LENGTH + 2):\n",
    "            \n",
    "            decoder_input_letter = decoder_input[:, num_letter, :].unsqueeze(1)\n",
    "            \n",
    "            decoder_output, decoder_hidden, attn_weights = Decoder_model(decoder_input_letter, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            if num_letter == 0:\n",
    "                \n",
    "                decoder_output_total = decoder_output\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                decoder_output_total = torch.cat((decoder_output_total, decoder_output), dim = 1)\n",
    "\n",
    "        output_indices = torch.tensor(list(range(0, MAX_LENGTH + 2 -1))).cuda(1) # removing last token from the output\n",
    "        decoder_output = torch.index_select(decoder_output_total, dim = 1, index = output_indices)\n",
    "\n",
    "        ground_truth = torch.argmax(decoder_input, dim = 2)\n",
    "        target_indices = torch.tensor(list(range(1, MAX_LENGTH + 2))).cuda(1) # remove SOS token from the input\n",
    "        ground_truth = torch.index_select(ground_truth, dim = 1, index = target_indices)\n",
    "\n",
    "        loss = calculate_loss(decoder_output, ground_truth, 16)\n",
    "\n",
    "        CNN_optimizer.zero_grad()\n",
    "        Encoder_optimizer.zero_grad()\n",
    "        Decoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        CNN_optimizer.step()\n",
    "        Encoder_optimizer.step()\n",
    "        Decoder_optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "    return np.mean(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    valid_losses = []\n",
    "\n",
    "    with torch.no_grad():       \n",
    "        for num_batch_val, (image_val, labels_val) in enumerate(val_loader):        \n",
    "            num_batch_val += 1\n",
    "            encoder_hidden_val = Encoder_model.initHidden()\n",
    "            image_cnn_val = image_val.view(-1, 1, 48, 10).cuda(1)\n",
    "            encoder_input_val = CNN_model(image_cnn_val)\n",
    "            encoder_outputs_val, encoder_hidden_val = Encoder_model(encoder_input_val, encoder_hidden_val)\n",
    "        \n",
    "            decoder_hidden_val = encoder_hidden_val\n",
    "            decoder_input_val = get_one_hot_target(labels=labels_val, seq_len = MAX_LENGTH + 2, output_size = 29, batch_size = 16).cuda(1)\n",
    "            \n",
    "            \n",
    "            for num_letter_val in range(MAX_LENGTH + 2):\n",
    "            \n",
    "                decoder_input_letter_val = decoder_input_val[:, num_letter_val, :].unsqueeze(1)\n",
    "\n",
    "                decoder_output_val, decoder_hidden_val, attn_weights_val = Decoder_model(decoder_input_letter_val, decoder_hidden_val, encoder_outputs_val)\n",
    "\n",
    "                if num_letter_val == 0:\n",
    "\n",
    "                    decoder_output_total_val = decoder_output_val\n",
    "\n",
    "                else:\n",
    "\n",
    "                    decoder_output_total_val = torch.cat((decoder_output_total_val, decoder_output_val), dim = 1)\n",
    "\n",
    "            \n",
    "            output_indices_val = torch.tensor(list(range(0, MAX_LENGTH + 2 - 1))).cuda(1) # remove last token from the output\n",
    "            decoder_output_val = torch.index_select(decoder_output_total_val, dim = 1, index = output_indices_val)\n",
    "\n",
    "            ground_truth_val = torch.argmax(decoder_input_val, dim = 2)\n",
    "            target_indices_val = torch.tensor(list(range(1, MAX_LENGTH + 2))).cuda(1) # remove START token from the input\n",
    "            ground_truth_val = torch.index_select(ground_truth_val, dim = 1, index = target_indices_val)\n",
    "            \n",
    "            loss_val = calculate_loss(decoder_output_val, ground_truth_val, 16)\n",
    "            valid_losses.append(loss_val.item())\n",
    "    return np.mean(valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patience():\n",
    "    \n",
    "    def __init__(self, patience):\n",
    "        self.patience = patience\n",
    "        self.current_patience = patience\n",
    "        self.min_loss_val = float('inf')\n",
    "\n",
    "    def more_patience(self,loss_val):\n",
    "        self.current_patience -= 1\n",
    "        if self.current_patience == 0:\n",
    "            return False\n",
    "\n",
    "        if loss_val < self.min_loss_val:\n",
    "            self.min_loss_val = loss_val\n",
    "            self.current_patience = patience\n",
    "\n",
    "            model_name = f\"{48}x{192}_by{10}_jump{2}_batch{16} NN_{4}_{1024}_{1}_{256} pats:{30000}\"\n",
    "            print(\", saved best model.\")\n",
    "            \n",
    "            torch.save({\n",
    "                'CNN_model_state_dict': CNN_model.state_dict(),\n",
    "                'CNN_optimizer_state_dict': CNN_optimizer.state_dict(),\n",
    "                'Encoder_model_state_dict': Encoder_model.state_dict(),\n",
    "                'Encoder_optimizer_state_dict': Encoder_optimizer.state_dict(),\n",
    "                'Decoder_model_state_dict': Decoder_model.state_dict(),\n",
    "                'Decoder_optimizer_state_dict': Decoder_optimizer.state_dict(),\n",
    "            }, 'Attention'+model_name)\n",
    "            \n",
    "            torch.save(CNN_model.state_dict(), 'CNN_'+model_name)\n",
    "            torch.save(Encoder_model.state_dict(), 'Encoder_'+model_name)\n",
    "            torch.save(Decoder_model.state_dict(), 'Decoder_'+model_name)\n",
    "    \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train loss: 2.0262378012793403 Valid loss: 1.6751467797064012 Duration: 1.5386393706003825 minutes\n",
      ", saved best model.\n",
      "Epoch: 1 Train loss: 1.552234000137874 Valid loss: 1.5168633768635411 Duration: 3.077888282140096 minutes\n",
      ", saved best model.\n",
      "Epoch: 2 Train loss: 1.4525571486609323 Valid loss: 1.449219826729067 Duration: 4.6056791067123415 minutes\n",
      ", saved best model.\n",
      "Epoch: 3 Train loss: 1.397971453973225 Valid loss: 1.4091694460761162 Duration: 6.135940114657084 minutes\n",
      ", saved best model.\n",
      "Epoch: 4 Train loss: 1.362684862749917 Valid loss: 1.3791308249196699 Duration: 7.664021257559458 minutes\n",
      ", saved best model.\n",
      "Epoch: 5 Train loss: 1.3380408314296177 Valid loss: 1.3577364269764192 Duration: 9.190347679456075 minutes\n",
      ", saved best model.\n",
      "Epoch: 6 Train loss: 1.3142182426452638 Valid loss: 1.336282085026464 Duration: 10.717403169473013 minutes\n",
      ", saved best model.\n",
      "Epoch: 7 Train loss: 1.2899985041618347 Valid loss: 1.3166916216573408 Duration: 12.240926973025005 minutes\n",
      ", saved best model.\n",
      "Epoch: 8 Train loss: 1.268632005589349 Valid loss: 1.2909173379021306 Duration: 13.766995922724407 minutes\n",
      ", saved best model.\n",
      "Epoch: 9 Train loss: 1.2483593513965607 Valid loss: 1.2853093320323574 Duration: 15.291865408420563 minutes\n",
      ", saved best model.\n",
      "Epoch: 10 Train loss: 1.2268998859609876 Valid loss: 1.2517640052303192 Duration: 16.794916931788126 minutes\n",
      ", saved best model.\n",
      "Epoch: 11 Train loss: 1.2041522717816489 Valid loss: 1.2278852289722813 Duration: 18.316897773742674 minutes\n",
      ", saved best model.\n",
      "Epoch: 12 Train loss: 1.1816581868103573 Valid loss: 1.2070593708945858 Duration: 19.843420529365538 minutes\n",
      ", saved best model.\n",
      "Epoch: 13 Train loss: 1.1607238687787738 Valid loss: 1.185229782135256 Duration: 21.360763585567476 minutes\n",
      ", saved best model.\n",
      "Epoch: 14 Train loss: 1.1410006107602801 Valid loss: 1.167823052214038 Duration: 22.88212143580119 minutes\n",
      ", saved best model.\n",
      "Epoch: 15 Train loss: 1.122926258632115 Valid loss: 1.1502845152731864 Duration: 24.400899561246238 minutes\n",
      ", saved best model.\n",
      "Epoch: 16 Train loss: 1.1047870468752725 Valid loss: 1.1405325589641448 Duration: 25.937413930892944 minutes\n",
      ", saved best model.\n",
      "Epoch: 17 Train loss: 1.088713411773954 Valid loss: 1.1197714449897889 Duration: 27.46818188428879 minutes\n",
      ", saved best model.\n",
      "Epoch: 18 Train loss: 1.0717855465752737 Valid loss: 1.1022827259955867 Duration: 29.001266900698344 minutes\n",
      ", saved best model.\n",
      "Epoch: 19 Train loss: 1.0560751926558358 Valid loss: 1.088246621431843 Duration: 30.525800828138987 minutes\n",
      ", saved best model.\n",
      "Epoch: 20 Train loss: 1.0409186623096467 Valid loss: 1.0725029687727652 Duration: 32.027058041095735 minutes\n",
      ", saved best model.\n",
      "Epoch: 21 Train loss: 1.0260447168690818 Valid loss: 1.0545500824528355 Duration: 33.53581410249074 minutes\n",
      ", saved best model.\n",
      "Epoch: 22 Train loss: 1.011552783352988 Valid loss: 1.039562213805414 Duration: 35.03081068197886 minutes\n",
      ", saved best model.\n",
      "Epoch: 23 Train loss: 0.9973948913982936 Valid loss: 1.029554691045515 Duration: 36.502108351389566 minutes\n",
      ", saved best model.\n",
      "Epoch: 24 Train loss: 0.9835174147742135 Valid loss: 1.0193817817395734 Duration: 37.914603090286256 minutes\n",
      ", saved best model.\n",
      "Epoch: 25 Train loss: 0.9706857170036861 Valid loss: 1.0100832398860686 Duration: 39.41289091507594 minutes\n",
      ", saved best model.\n",
      "Epoch: 26 Train loss: 0.9593515400545938 Valid loss: 0.9924473502943593 Duration: 40.91401838858922 minutes\n",
      ", saved best model.\n",
      "Epoch: 27 Train loss: 0.9467757537364959 Valid loss: 0.9882614016532898 Duration: 42.40300005674362 minutes\n",
      ", saved best model.\n",
      "Epoch: 28 Train loss: 0.9361210267203195 Valid loss: 0.9742437476111997 Duration: 43.89532778263092 minutes\n",
      ", saved best model.\n",
      "Epoch: 29 Train loss: 0.9248681384495326 Valid loss: 0.9599979471775794 Duration: 45.37956560452779 minutes\n",
      ", saved best model.\n",
      "Epoch: 30 Train loss: 0.9143327712331499 Valid loss: 0.9504149508091712 Duration: 46.841543118158974 minutes\n",
      ", saved best model.\n",
      "Epoch: 31 Train loss: 0.9041877540860858 Valid loss: 0.9416865494943434 Duration: 48.33093458414078 minutes\n",
      ", saved best model.\n",
      "Epoch: 32 Train loss: 0.8943076431410654 Valid loss: 0.9304398240581635 Duration: 49.837122519811 minutes\n",
      ", saved best model.\n",
      "Epoch: 33 Train loss: 0.8844013336726597 Valid loss: 0.9199701797577643 Duration: 51.33803119659424 minutes\n",
      ", saved best model.\n",
      "Epoch: 34 Train loss: 0.8751732334068844 Valid loss: 0.9087089050200677 Duration: 52.813981028397876 minutes\n",
      ", saved best model.\n",
      "Epoch: 35 Train loss: 0.866310262475695 Valid loss: 0.905012845993042 Duration: 54.25451460282008 minutes\n",
      ", saved best model.\n",
      "Epoch: 36 Train loss: 0.8573129683562688 Valid loss: 0.899134531136482 Duration: 55.76725609699885 minutes\n",
      ", saved best model.\n",
      "Epoch: 37 Train loss: 0.8488295595305306 Valid loss: 0.8846638029621493 Duration: 57.22313327789307 minutes\n",
      ", saved best model.\n",
      "Epoch: 38 Train loss: 0.8402606604439872 Valid loss: 0.8824914780355269 Duration: 58.693975524107614 minutes\n",
      ", saved best model.\n",
      "Epoch: 39 Train loss: 0.8343257940667016 Valid loss: 0.8736334731501918 Duration: 60.18267000118892 minutes\n",
      ", saved best model.\n",
      "Epoch: 40 Train loss: 0.826575665473938 Valid loss: 0.8619341013893005 Duration: 61.67168277104695 minutes\n",
      ", saved best model.\n",
      "Epoch: 41 Train loss: 0.8178239449943815 Valid loss: 0.8554090126868217 Duration: 63.15645523866018 minutes\n",
      ", saved best model.\n",
      "Epoch: 42 Train loss: 0.8111112010478974 Valid loss: 0.8523814428237176 Duration: 64.65107601086298 minutes\n",
      ", saved best model.\n",
      "Epoch: 43 Train loss: 0.8039965874637877 Valid loss: 0.8463539543651766 Duration: 66.14330749909082 minutes\n",
      ", saved best model.\n",
      "Epoch: 44 Train loss: 0.7969108970335552 Valid loss: 0.8394120922011714 Duration: 67.63514616489411 minutes\n",
      ", saved best model.\n",
      "Epoch: 45 Train loss: 0.7902448597635542 Valid loss: 0.8313602478273453 Duration: 69.12193549076716 minutes\n",
      ", saved best model.\n",
      "Epoch: 46 Train loss: 0.7834503734111786 Valid loss: 0.8278928355824563 Duration: 70.61927724679312 minutes\n",
      ", saved best model.\n",
      "Epoch: 47 Train loss: 0.777145254101072 Valid loss: 0.8178140160537535 Duration: 72.1303501923879 minutes\n",
      ", saved best model.\n",
      "Epoch: 48 Train loss: 0.7709141425575529 Valid loss: 0.8122570601201826 Duration: 73.60824466943741 minutes\n",
      ", saved best model.\n",
      "Epoch: 49 Train loss: 0.7642060785634177 Valid loss: 0.8077197440208927 Duration: 75.07354145050049 minutes\n",
      ", saved best model.\n",
      "Epoch: 50 Train loss: 0.7582961923224585 Valid loss: 0.8030885034991849 Duration: 76.53398266235988 minutes\n",
      ", saved best model.\n",
      "Epoch: 51 Train loss: 0.7523897731474468 Valid loss: 0.7947790641938487 Duration: 78.02979358434678 minutes\n",
      ", saved best model.\n",
      "Epoch: 52 Train loss: 0.7461932945081166 Valid loss: 0.7931159854896607 Duration: 79.49534811178843 minutes\n",
      ", saved best model.\n",
      "Epoch: 53 Train loss: 0.7402934011731829 Valid loss: 0.7843963354825974 Duration: 80.99123884042105 minutes\n",
      ", saved best model.\n",
      "Epoch: 54 Train loss: 0.7349217923879623 Valid loss: 0.7787130600021731 Duration: 82.50086710055669 minutes\n",
      ", saved best model.\n",
      "Epoch: 55 Train loss: 0.7294412667581013 Valid loss: 0.7713611423969269 Duration: 84.00014487504959 minutes\n",
      ", saved best model.\n",
      "Epoch: 56 Train loss: 0.7236471440110888 Valid loss: 0.7673001659493293 Duration: 85.5034820040067 minutes\n",
      ", saved best model.\n",
      "Epoch: 57 Train loss: 0.7181652174166271 Valid loss: 0.7609034911278756 Duration: 87.00420597791671 minutes\n",
      ", saved best model.\n",
      "Epoch: 58 Train loss: 0.7125194414513452 Valid loss: 0.7577404004912223 Duration: 88.50689334869385 minutes\n",
      ", saved best model.\n",
      "Epoch: 59 Train loss: 0.707318977202688 Valid loss: 0.7520622769671101 Duration: 89.9771799882253 minutes\n",
      ", saved best model.\n",
      "Epoch: 60 Train loss: 0.7021984868901117 Valid loss: 0.7474704327121857 Duration: 91.45824734767278 minutes\n",
      ", saved best model.\n",
      "Epoch: 61 Train loss: 0.6968301402500697 Valid loss: 0.7431826947196838 Duration: 92.9478468298912 minutes\n",
      ", saved best model.\n",
      "Epoch: 62 Train loss: 0.6927597953762327 Valid loss: 0.7387745841856925 Duration: 94.44803160826365 minutes\n",
      ", saved best model.\n",
      "Epoch: 63 Train loss: 0.6887632563284465 Valid loss: 0.7330640698632886 Duration: 95.95439585447312 minutes\n",
      ", saved best model.\n",
      "Epoch: 64 Train loss: 0.6834551721640996 Valid loss: 0.730006488100175 Duration: 97.45297701358795 minutes\n",
      ", saved best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 Train loss: 0.6793209478514535 Valid loss: 0.7244130916172459 Duration: 98.96332377195358 minutes\n",
      ", saved best model.\n",
      "Epoch: 66 Train loss: 0.6744405015196119 Valid loss: 0.7187133575639417 Duration: 100.43000594774882 minutes\n",
      ", saved best model.\n",
      "Epoch: 67 Train loss: 0.6693591668605804 Valid loss: 0.7139950673426351 Duration: 101.93579049905141 minutes\n",
      ", saved best model.\n",
      "Epoch: 68 Train loss: 0.6646596863951002 Valid loss: 0.708914692844114 Duration: 103.40894486109416 minutes\n",
      ", saved best model.\n",
      "Epoch: 69 Train loss: 0.6598620338950838 Valid loss: 0.7041470898735908 Duration: 104.91827701330185 minutes\n",
      ", saved best model.\n",
      "Epoch: 70 Train loss: 0.6551266946281705 Valid loss: 0.7006894801893542 Duration: 106.40257918437322 minutes\n",
      ", saved best model.\n",
      "Epoch: 71 Train loss: 0.649954145022801 Valid loss: 0.6940914555903404 Duration: 107.88934723536174 minutes\n",
      ", saved best model.\n",
      "Epoch: 72 Train loss: 0.6447508984633854 Valid loss: 0.6951710403926911 Duration: 109.36372276147206 minutes\n",
      "Epoch: 73 Train loss: 0.6401032292161669 Valid loss: 0.6860260314518406 Duration: 110.85179692904154 minutes\n",
      ", saved best model.\n",
      "Epoch: 74 Train loss: 0.6361254593474525 Valid loss: 0.6846528495511701 Duration: 112.31943290233612 minutes\n",
      ", saved best model.\n",
      "Epoch: 75 Train loss: 0.6313331608601979 Valid loss: 0.6726270342065442 Duration: 113.80394390821456 minutes\n",
      ", saved best model.\n",
      "Epoch: 76 Train loss: 0.6268721220833915 Valid loss: 0.6698172183767441 Duration: 115.30531183083852 minutes\n",
      ", saved best model.\n",
      "Epoch: 77 Train loss: 0.6223423980985369 Valid loss: 0.6724628315817925 Duration: 116.74465613762537 minutes\n",
      "Epoch: 78 Train loss: 0.6190802649600166 Valid loss: 0.6641568070457827 Duration: 118.22533004283905 minutes\n",
      ", saved best model.\n",
      "Epoch: 79 Train loss: 0.6155521626302174 Valid loss: 0.66267359737427 Duration: 119.7135073741277 minutes\n",
      ", saved best model.\n",
      "Epoch: 80 Train loss: 0.6109989511966706 Valid loss: 0.6600933382588048 Duration: 121.21196268002193 minutes\n",
      ", saved best model.\n",
      "Epoch: 81 Train loss: 0.6069083705118724 Valid loss: 0.6557040310675099 Duration: 122.67613366047541 minutes\n",
      ", saved best model.\n",
      "Epoch: 82 Train loss: 0.6028722295079912 Valid loss: 0.6496736075608961 Duration: 124.09013080596924 minutes\n",
      ", saved best model.\n",
      "Epoch: 83 Train loss: 0.5988116734027863 Valid loss: 0.6479153229344276 Duration: 125.58388833204906 minutes\n",
      ", saved best model.\n",
      "Epoch: 84 Train loss: 0.5949770548854555 Valid loss: 0.6512502528006031 Duration: 127.08696551720301 minutes\n",
      "Epoch: 85 Train loss: 0.5911884835617883 Valid loss: 0.6397493813307055 Duration: 128.5726436416308 minutes\n",
      ", saved best model.\n",
      "Epoch: 86 Train loss: 0.5865450500420162 Valid loss: 0.6382844174100507 Duration: 130.06803679068884 minutes\n",
      ", saved best model.\n",
      "Epoch: 87 Train loss: 0.5819813904251371 Valid loss: 0.6331597172444866 Duration: 131.53397338390351 minutes\n",
      ", saved best model.\n",
      "Epoch: 88 Train loss: 0.5783776045186179 Valid loss: 0.6326053027183779 Duration: 133.03929706414542 minutes\n",
      ", saved best model.\n",
      "Epoch: 89 Train loss: 0.577755751490593 Valid loss: 0.6320787610546235 Duration: 134.51300615866978 minutes\n",
      ", saved best model.\n",
      "Epoch: 90 Train loss: 0.5777427056176322 Valid loss: 0.6255505940606517 Duration: 136.02345892190934 minutes\n",
      ", saved best model.\n",
      "Epoch: 91 Train loss: 0.5689428134645734 Valid loss: 0.615673073837834 Duration: 137.52133407592774 minutes\n",
      ", saved best model.\n",
      "Epoch: 92 Train loss: 0.5633143676689693 Valid loss: 0.618776261806488 Duration: 139.0252562125524 minutes\n",
      "Epoch: 93 Train loss: 0.5597428248780114 Valid loss: 0.6078685440363423 Duration: 140.50420428117116 minutes\n",
      ", saved best model.\n",
      "Epoch: 94 Train loss: 0.5559043192522867 Valid loss: 0.6074857610848642 Duration: 141.99223649104437 minutes\n",
      ", saved best model.\n",
      "Epoch: 95 Train loss: 0.552588706953185 Valid loss: 0.6064888411952604 Duration: 143.4936680873235 minutes\n",
      ", saved best model.\n",
      "Epoch: 96 Train loss: 0.5522045888219561 Valid loss: 0.6131242927043669 Duration: 144.98823058605194 minutes\n",
      "Epoch: 97 Train loss: 0.5482948021377836 Valid loss: 0.5987777234085144 Duration: 146.47780484755833 minutes\n",
      ", saved best model.\n",
      "Epoch: 98 Train loss: 0.5510831016472407 Valid loss: 0.6017787374796406 Duration: 147.97837098439535 minutes\n",
      "Epoch: 99 Train loss: 0.5509878849472318 Valid loss: 0.6015552056412543 Duration: 149.48062258561453 minutes\n",
      "Epoch: 100 Train loss: 0.5484995398691722 Valid loss: 0.5999028629833653 Duration: 150.97418115139007 minutes\n",
      "Epoch: 101 Train loss: 0.5447035719667163 Valid loss: 0.5988147739441164 Duration: 152.46385746002198 minutes\n",
      "Epoch: 102 Train loss: 0.5407937722887312 Valid loss: 0.5888321668870987 Duration: 153.93731286525727 minutes\n",
      ", saved best model.\n",
      "Epoch: 103 Train loss: 0.5359309741088322 Valid loss: 0.5886117412197974 Duration: 155.43458940585455 minutes\n",
      ", saved best model.\n",
      "Epoch: 104 Train loss: 0.5288421017442431 Valid loss: 0.579109761503435 Duration: 156.93642925818762 minutes\n",
      ", saved best model.\n",
      "Epoch: 105 Train loss: 0.525677009173802 Valid loss: 0.5816278423993818 Duration: 158.43519672552745 minutes\n",
      "Epoch: 106 Train loss: 0.5233650162730898 Valid loss: 0.5798602099380186 Duration: 159.88476550976435 minutes\n",
      "Epoch: 107 Train loss: 0.5224065638099398 Valid loss: 0.5753336221941056 Duration: 161.32649744351704 minutes\n",
      ", saved best model.\n",
      "Epoch: 108 Train loss: 0.5167802084173475 Valid loss: 0.5665422149242894 Duration: 162.82979717652003 minutes\n",
      ", saved best model.\n",
      "Epoch: 109 Train loss: 0.5141856139728002 Valid loss: 0.5756238852777789 Duration: 164.3334107240041 minutes\n",
      "Epoch: 110 Train loss: 0.5185889081784657 Valid loss: 0.5713952582690024 Duration: 165.82770889202754 minutes\n",
      "Epoch: 111 Train loss: 0.509987959589277 Valid loss: 0.5593760777865687 Duration: 167.27949743270875 minutes\n",
      ", saved best model.\n",
      "Epoch: 112 Train loss: 0.5052384323392596 Valid loss: 0.5602264274512568 Duration: 168.77599532206852 minutes\n",
      "Epoch: 113 Train loss: 0.5016113432986395 Valid loss: 0.5545520960323272 Duration: 170.25867237250011 minutes\n",
      ", saved best model.\n",
      "Epoch: 114 Train loss: 0.5009825920547758 Valid loss: 0.5555398901624065 Duration: 171.76452269951503 minutes\n",
      "Epoch: 115 Train loss: 0.49599286976030893 Valid loss: 0.5463149643713429 Duration: 173.2690196633339 minutes\n",
      ", saved best model.\n",
      "Epoch: 116 Train loss: 0.49286657987322124 Valid loss: 0.5471441404473397 Duration: 174.77215614318848 minutes\n",
      "Epoch: 117 Train loss: 0.4914270695277623 Valid loss: 0.5420674864322909 Duration: 176.2767619172732 minutes\n",
      ", saved best model.\n",
      "Epoch: 118 Train loss: 0.4864549525294985 Valid loss: 0.542300050297091 Duration: 177.75329515536626 minutes\n",
      "Epoch: 119 Train loss: 0.48357822915485926 Valid loss: 0.5353793521081248 Duration: 179.2519443710645 minutes\n",
      ", saved best model.\n",
      "Epoch: 120 Train loss: 0.4833163670897484 Valid loss: 0.5343273407028567 Duration: 180.7609547694524 minutes\n",
      ", saved best model.\n",
      "Epoch: 121 Train loss: 0.480486543740545 Valid loss: 0.5301750835872465 Duration: 182.26742766300836 minutes\n",
      ", saved best model.\n",
      "Epoch: 122 Train loss: 0.4746586790766035 Valid loss: 0.5303246422160056 Duration: 183.75830318530402 minutes\n",
      "Epoch: 123 Train loss: 0.47213699982847485 Valid loss: 0.5260612065753629 Duration: 185.26653584241868 minutes\n",
      ", saved best model.\n",
      "Epoch: 124 Train loss: 0.46920572766235896 Valid loss: 0.5269800088097972 Duration: 186.77377822001776 minutes\n",
      "Epoch: 125 Train loss: 0.4673365815281868 Valid loss: 0.5221735849495857 Duration: 188.27536073128383 minutes\n",
      ", saved best model.\n",
      "Epoch: 126 Train loss: 0.4635889519708497 Valid loss: 0.5182380719530967 Duration: 189.7784906387329 minutes\n",
      ", saved best model.\n",
      "Epoch: 127 Train loss: 0.4609458834018026 Valid loss: 0.5149724132591679 Duration: 191.26018670399984 minutes\n",
      ", saved best model.\n",
      "Epoch: 128 Train loss: 0.4580254712785993 Valid loss: 0.5149993276403796 Duration: 192.73044841686885 minutes\n",
      "Epoch: 129 Train loss: 0.45623506512812206 Valid loss: 0.5092462998244071 Duration: 194.22390585343044 minutes\n",
      ", saved best model.\n",
      "Epoch: 130 Train loss: 0.45329306475605285 Valid loss: 0.5057223234926501 Duration: 195.72032412687938 minutes\n",
      ", saved best model.\n",
      "Epoch: 131 Train loss: 0.4502836972219603 Valid loss: 0.5045191039962154 Duration: 197.2072413365046 minutes\n",
      ", saved best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132 Train loss: 0.4481978247676577 Valid loss: 0.5035820540881926 Duration: 198.67293951511382 minutes\n",
      ", saved best model.\n",
      "Epoch: 133 Train loss: 0.45093062539611545 Valid loss: 0.5086714680637082 Duration: 200.09999171495437 minutes\n",
      "Epoch: 134 Train loss: 0.45232991268805095 Valid loss: 0.5071390944142495 Duration: 201.59702812433244 minutes\n",
      "Epoch: 135 Train loss: 0.4490302226969174 Valid loss: 0.4983093325168856 Duration: 203.08419292767843 minutes\n",
      ", saved best model.\n",
      "Epoch: 136 Train loss: 0.4438482653583799 Valid loss: 0.49888236580356476 Duration: 204.58079372644426 minutes\n",
      "Epoch: 137 Train loss: 0.44223463428871973 Valid loss: 0.49515367083011136 Duration: 206.07934842507044 minutes\n",
      ", saved best model.\n",
      "Epoch: 138 Train loss: 0.43981887263059616 Valid loss: 0.4883588946634723 Duration: 207.58512667020162 minutes\n",
      ", saved best model.\n",
      "Epoch: 139 Train loss: 0.43345798206329345 Valid loss: 0.4879675012442373 Duration: 209.09300603866578 minutes\n",
      ", saved best model.\n",
      "Epoch: 140 Train loss: 0.4292628856897354 Valid loss: 0.48794838665954526 Duration: 210.59894489447277 minutes\n",
      ", saved best model.\n",
      "Epoch: 141 Train loss: 0.4267412834422929 Valid loss: 0.4819428526586102 Duration: 212.09832369486492 minutes\n",
      ", saved best model.\n",
      "Epoch: 142 Train loss: 0.4227121286221913 Valid loss: 0.4756329266294356 Duration: 213.60640868345897 minutes\n",
      ", saved best model.\n",
      "Epoch: 143 Train loss: 0.4197731482045991 Valid loss: 0.47234643635249907 Duration: 215.12437082131703 minutes\n",
      ", saved best model.\n",
      "Epoch: 144 Train loss: 0.41882499577317917 Valid loss: 0.4730047436971818 Duration: 216.5935555100441 minutes\n",
      "Epoch: 145 Train loss: 0.41450027894973757 Valid loss: 0.46886381194476157 Duration: 218.0925219019254 minutes\n",
      ", saved best model.\n",
      "Epoch: 146 Train loss: 0.41198449045419694 Valid loss: 0.4663243079858442 Duration: 219.60470414559046 minutes\n",
      ", saved best model.\n",
      "Epoch: 147 Train loss: 0.4097387614250183 Valid loss: 0.46407928389887654 Duration: 221.10917613506317 minutes\n",
      ", saved best model.\n",
      "Epoch: 148 Train loss: 0.4069109542284693 Valid loss: 0.4620662139308068 Duration: 222.583007756869 minutes\n",
      ", saved best model.\n",
      "Epoch: 149 Train loss: 0.40478318122455054 Valid loss: 0.45847209182477766 Duration: 224.07448518276215 minutes\n",
      ", saved best model.\n",
      "Epoch: 150 Train loss: 0.40264491377558026 Valid loss: 0.456996705503233 Duration: 225.57146613995235 minutes\n",
      ", saved best model.\n",
      "Epoch: 151 Train loss: 0.3994904894573348 Valid loss: 0.45231383726481467 Duration: 227.0635926604271 minutes\n",
      ", saved best model.\n",
      "Epoch: 152 Train loss: 0.3971947137628283 Valid loss: 0.45474317285322374 Duration: 228.52989149490992 minutes\n",
      "Epoch: 153 Train loss: 0.3966363327758653 Valid loss: 0.44954377845410376 Duration: 229.9902592221896 minutes\n",
      ", saved best model.\n",
      "Epoch: 154 Train loss: 0.3921505895938192 Valid loss: 0.44659110278852526 Duration: 231.46889785528182 minutes\n",
      ", saved best model.\n",
      "Epoch: 155 Train loss: 0.39039203171219145 Valid loss: 0.44690691992159814 Duration: 232.96934738953908 minutes\n",
      "Epoch: 156 Train loss: 0.38826988156352726 Valid loss: 0.4439020291451485 Duration: 234.45901889006296 minutes\n",
      ", saved best model.\n",
      "Epoch: 157 Train loss: 0.3848789250084332 Valid loss: 0.43780585955227574 Duration: 235.95565456151962 minutes\n",
      ", saved best model.\n",
      "Epoch: 158 Train loss: 0.3841683192338262 Valid loss: 0.4350016340613365 Duration: 237.44664736588797 minutes\n",
      ", saved best model.\n",
      "Epoch: 159 Train loss: 0.3797040492807116 Valid loss: 0.4365322270220326 Duration: 238.95185432036718 minutes\n",
      "Epoch: 160 Train loss: 0.37757957129819053 Valid loss: 0.43184265638551406 Duration: 240.45088283220926 minutes\n",
      ", saved best model.\n",
      "Epoch: 161 Train loss: 0.37519259738922117 Valid loss: 0.42801862907025123 Duration: 241.95639814535778 minutes\n",
      ", saved best model.\n",
      "Epoch: 162 Train loss: 0.373051286646298 Valid loss: 0.4278430941124116 Duration: 243.4536278605461 minutes\n",
      ", saved best model.\n",
      "Epoch: 163 Train loss: 0.3711774181808744 Valid loss: 0.42530478873560507 Duration: 244.95483037233353 minutes\n",
      ", saved best model.\n",
      "Epoch: 164 Train loss: 0.3681090567282268 Valid loss: 0.4248150940383634 Duration: 246.45388450225195 minutes\n",
      ", saved best model.\n",
      "Epoch: 165 Train loss: 0.3687104041491236 Valid loss: 0.4218700643508665 Duration: 247.92351438999177 minutes\n",
      ", saved best model.\n",
      "Epoch: 166 Train loss: 0.3645383785877909 Valid loss: 0.4210861695389594 Duration: 249.39569547176362 minutes\n",
      ", saved best model.\n",
      "Epoch: 167 Train loss: 0.3627417361991746 Valid loss: 0.42044166595705096 Duration: 250.88627939621608 minutes\n",
      ", saved best model.\n",
      "Epoch: 168 Train loss: 0.36079497713702063 Valid loss: 0.42116057247884814 Duration: 252.38168734312057 minutes\n",
      "Epoch: 169 Train loss: 0.3581617628931999 Valid loss: 0.41138670112817516 Duration: 253.8932192603747 minutes\n",
      ", saved best model.\n",
      "Epoch: 170 Train loss: 0.35481355139187404 Valid loss: 0.4119018792144714 Duration: 255.38928271929424 minutes\n",
      "Epoch: 171 Train loss: 0.35253388616016934 Valid loss: 0.413992564764715 Duration: 256.8749569058418 minutes\n",
      "Epoch: 172 Train loss: 0.35556253345949307 Valid loss: 0.41116839551156564 Duration: 258.36815651655195 minutes\n",
      ", saved best model.\n",
      "Epoch: 173 Train loss: 0.35153853373868127 Valid loss: 0.40980134736145696 Duration: 259.84896930853523 minutes\n",
      ", saved best model.\n",
      "Epoch: 174 Train loss: 0.3460199176328523 Valid loss: 0.4050507860318307 Duration: 261.3244174281756 minutes\n",
      ", saved best model.\n",
      "Epoch: 175 Train loss: 0.34305758407286235 Valid loss: 0.39415597867581154 Duration: 262.840735467275 minutes\n",
      ", saved best model.\n",
      "Epoch: 176 Train loss: 0.3404427227803639 Valid loss: 0.39746986065180073 Duration: 264.3481157978376 minutes\n",
      "Epoch: 177 Train loss: 0.3388059872984886 Valid loss: 0.40521830440528933 Duration: 265.79533491929374 minutes\n",
      "Epoch: 178 Train loss: 0.3402510335786002 Valid loss: 0.39413203106772515 Duration: 267.2939489920934 minutes\n",
      ", saved best model.\n",
      "Epoch: 179 Train loss: 0.3378169375232288 Valid loss: 0.390626844619551 Duration: 268.7507430036863 minutes\n",
      ", saved best model.\n",
      "Epoch: 180 Train loss: 0.3349125240274838 Valid loss: 0.38999624982956915 Duration: 270.23193746407827 minutes\n",
      ", saved best model.\n",
      "Epoch: 181 Train loss: 0.3336320746924196 Valid loss: 0.38628617313600355 Duration: 271.7394685268402 minutes\n",
      ", saved best model.\n",
      "Epoch: 182 Train loss: 0.3296438111748014 Valid loss: 0.38297066525105505 Duration: 273.228140715758 minutes\n",
      ", saved best model.\n",
      "Epoch: 183 Train loss: 0.32742487803527287 Valid loss: 0.3789477122406806 Duration: 274.6709046204885 minutes\n",
      ", saved best model.\n",
      "Epoch: 184 Train loss: 0.32654575800044194 Valid loss: 0.37974616452570886 Duration: 276.15729315280913 minutes\n",
      "Epoch: 185 Train loss: 0.3243697874971799 Valid loss: 0.3808617361130253 Duration: 277.6520677924156 minutes\n",
      "Epoch: 186 Train loss: 0.3202223423889705 Valid loss: 0.3753389172977017 Duration: 279.06920820474625 minutes\n",
      ", saved best model.\n",
      "Epoch: 187 Train loss: 0.3167261606539999 Valid loss: 0.36765616675538404 Duration: 280.56893897453944 minutes\n",
      ", saved best model.\n",
      "Epoch: 188 Train loss: 0.3144400782414845 Valid loss: 0.36566552639968936 Duration: 282.0396628379822 minutes\n",
      ", saved best model.\n",
      "Epoch: 189 Train loss: 0.3127559084551675 Valid loss: 0.37002545691305594 Duration: 283.5467412869136 minutes\n",
      "Epoch: 190 Train loss: 0.3103940152440752 Valid loss: 0.3631760665485936 Duration: 285.0452711224556 minutes\n",
      ", saved best model.\n",
      "Epoch: 191 Train loss: 0.3097606482420649 Valid loss: 0.3646395134349023 Duration: 286.54741494258246 minutes\n",
      "Epoch: 192 Train loss: 0.3063332164798464 Valid loss: 0.36477470854597704 Duration: 288.0562416871389 minutes\n",
      "Epoch: 193 Train loss: 0.3042014513569219 Valid loss: 0.3590030504330512 Duration: 289.5714136282603 minutes\n",
      ", saved best model.\n",
      "Epoch: 194 Train loss: 0.3024958571706499 Valid loss: 0.3521207270603026 Duration: 291.07217030127845 minutes\n",
      ", saved best model.\n",
      "Epoch: 195 Train loss: 0.30019367881332126 Valid loss: 0.3526041803340758 Duration: 292.5646231849988 minutes\n",
      "Epoch: 196 Train loss: 0.29821632002506937 Valid loss: 0.3588923297582134 Duration: 294.0628321409225 minutes\n",
      "Epoch: 197 Train loss: 0.29752903851440976 Valid loss: 0.34893536711892775 Duration: 295.56088339885076 minutes\n",
      ", saved best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 198 Train loss: 0.29415324132357323 Valid loss: 0.34672690639572756 Duration: 297.0524024883906 minutes\n",
      ", saved best model.\n",
      "Epoch: 199 Train loss: 0.2921852967951979 Valid loss: 0.3460968806137962 Duration: 298.50347618261975 minutes\n",
      ", saved best model.\n",
      "Epoch: 200 Train loss: 0.29042069648844854 Valid loss: 0.34322397098425894 Duration: 300.00827283064524 minutes\n",
      ", saved best model.\n",
      "Epoch: 201 Train loss: 0.2887121055041041 Valid loss: 0.34188925402779735 Duration: 301.5164472063382 minutes\n",
      ", saved best model.\n",
      "Epoch: 202 Train loss: 0.2862545535138675 Valid loss: 0.33895448811592593 Duration: 303.02321326732635 minutes\n",
      ", saved best model.\n",
      "Epoch: 203 Train loss: 0.2847559034824371 Valid loss: 0.33722089543457956 Duration: 304.5336232662201 minutes\n",
      ", saved best model.\n",
      "Epoch: 204 Train loss: 0.28297613781690595 Valid loss: 0.3363954563054346 Duration: 305.98781937360764 minutes\n",
      ", saved best model.\n",
      "Epoch: 205 Train loss: 0.28137518805691175 Valid loss: 0.3324240249010824 Duration: 307.459881790479 minutes\n",
      ", saved best model.\n",
      "Epoch: 206 Train loss: 0.279096742945058 Valid loss: 0.33229725255120185 Duration: 308.9565598607063 minutes\n",
      ", saved best model.\n",
      "Epoch: 207 Train loss: 0.2775614320167473 Valid loss: 0.3310045897960663 Duration: 310.44913730223976 minutes\n",
      ", saved best model.\n",
      "Epoch: 208 Train loss: 0.27547807421854564 Valid loss: 0.3343462932013696 Duration: 311.9031255086263 minutes\n",
      "Epoch: 209 Train loss: 0.2744674131316798 Valid loss: 0.328070031659257 Duration: 313.40492163101834 minutes\n",
      ", saved best model.\n",
      "Epoch: 210 Train loss: 0.2736041746224676 Valid loss: 0.3230234522732996 Duration: 314.9040721376737 minutes\n",
      ", saved best model.\n",
      "Epoch: 211 Train loss: 0.2703625996027674 Valid loss: 0.3217769041657448 Duration: 316.3904520750046 minutes\n",
      ", saved best model.\n",
      "Epoch: 212 Train loss: 0.2686529094406537 Valid loss: 0.3212145881787423 Duration: 317.88856552441916 minutes\n",
      ", saved best model.\n",
      "Epoch: 213 Train loss: 0.2668808211684227 Valid loss: 0.31906197027814004 Duration: 319.38902928431827 minutes\n",
      ", saved best model.\n",
      "Epoch: 214 Train loss: 0.26545040471213205 Valid loss: 0.3157291551751475 Duration: 320.862935423851 minutes\n",
      ", saved best model.\n",
      "Epoch: 215 Train loss: 0.2634344192956175 Valid loss: 0.3240306788394528 Duration: 322.34965717395147 minutes\n",
      "Epoch: 216 Train loss: 0.26180263756428446 Valid loss: 0.32383554044269747 Duration: 323.8536422173182 minutes\n",
      "Epoch: 217 Train loss: 0.2602776386354651 Valid loss: 0.31309502487701757 Duration: 325.3606157541275 minutes\n",
      ", saved best model.\n",
      "Epoch: 218 Train loss: 0.25852425312570165 Valid loss: 0.3109166166715084 Duration: 326.83673624197644 minutes\n",
      ", saved best model.\n",
      "Epoch: 219 Train loss: 0.25711960337417467 Valid loss: 0.3108257257169293 Duration: 328.28440644741056 minutes\n",
      ", saved best model.\n",
      "Epoch: 220 Train loss: 0.25518689175588744 Valid loss: 0.3106087609644859 Duration: 329.71195058822633 minutes\n",
      ", saved best model.\n",
      "Epoch: 221 Train loss: 0.2541802160867623 Valid loss: 0.3079106196040107 Duration: 331.205840086937 minutes\n",
      ", saved best model.\n",
      "Epoch: 222 Train loss: 0.25194933302487643 Valid loss: 0.30576327142696225 Duration: 332.6646200617154 minutes\n",
      ", saved best model.\n",
      "Epoch: 223 Train loss: 0.2540373822450638 Valid loss: 0.3153387796013586 Duration: 334.16430430412294 minutes\n",
      "Epoch: 224 Train loss: 0.2518642324379512 Valid loss: 0.3024367382449488 Duration: 335.68029998938243 minutes\n",
      ", saved best model.\n",
      "Epoch: 225 Train loss: 0.24863082617521287 Valid loss: 0.3017109512321411 Duration: 337.16849660873413 minutes\n",
      ", saved best model.\n",
      "Epoch: 226 Train loss: 0.24723519251602036 Valid loss: 0.2980578122360091 Duration: 338.6464190006256 minutes\n",
      ", saved best model.\n",
      "Epoch: 227 Train loss: 0.24434511744976042 Valid loss: 0.2967178315645264 Duration: 340.13509743213655 minutes\n",
      ", saved best model.\n",
      "Epoch: 228 Train loss: 0.2433489324407918 Valid loss: 0.2949224224975032 Duration: 341.62221578359606 minutes\n",
      ", saved best model.\n",
      "Epoch: 229 Train loss: 0.24193774837681226 Valid loss: 0.29335945087575144 Duration: 343.114786028862 minutes\n",
      ", saved best model.\n",
      "Epoch: 230 Train loss: 0.24354176347596304 Valid loss: 0.2913338730652486 Duration: 344.60282886425654 minutes\n",
      ", saved best model.\n",
      "Epoch: 231 Train loss: 0.23891600789342607 Valid loss: 0.29445768339980033 Duration: 346.1115466872851 minutes\n",
      "Epoch: 232 Train loss: 0.23873463747331075 Valid loss: 0.28891796835007205 Duration: 347.6066784620285 minutes\n",
      ", saved best model.\n",
      "Epoch: 233 Train loss: 0.23587513263736454 Valid loss: 0.28827970270668307 Duration: 349.1126499613126 minutes\n",
      ", saved best model.\n",
      "Epoch: 234 Train loss: 0.23466443714499474 Valid loss: 0.28985735653869565 Duration: 350.6041908224424 minutes\n",
      "Epoch: 235 Train loss: 0.23344360577634402 Valid loss: 0.2855303095233056 Duration: 352.1074035525322 minutes\n",
      ", saved best model.\n",
      "Epoch: 236 Train loss: 0.23310737898945808 Valid loss: 0.28461381264271274 Duration: 353.5871255238851 minutes\n",
      ", saved best model.\n",
      "Epoch: 237 Train loss: 0.23027369864923614 Valid loss: 0.2824822986318219 Duration: 355.0835685213407 minutes\n",
      ", saved best model.\n",
      "Epoch: 238 Train loss: 0.22979022845625877 Valid loss: 0.28185814354688893 Duration: 356.5871448238691 minutes\n",
      ", saved best model.\n",
      "Epoch: 239 Train loss: 0.22839365266050612 Valid loss: 0.2826224255465692 Duration: 358.08598531881967 minutes\n",
      "Epoch: 240 Train loss: 0.22665142509766986 Valid loss: 0.28062342119313055 Duration: 359.57836883068086 minutes\n",
      ", saved best model.\n",
      "Epoch: 241 Train loss: 0.22673695173220976 Valid loss: 0.2767023978935134 Duration: 361.07943346500394 minutes\n",
      ", saved best model.\n",
      "Epoch: 242 Train loss: 0.22396872772063528 Valid loss: 0.2800743505358696 Duration: 362.5741566697756 minutes\n",
      "Epoch: 243 Train loss: 0.22287905406526157 Valid loss: 0.27517336150330884 Duration: 364.07390216588976 minutes\n",
      ", saved best model.\n",
      "Epoch: 244 Train loss: 0.2220169133927141 Valid loss: 0.2733854606987969 Duration: 365.57128934462867 minutes\n",
      ", saved best model.\n",
      "Epoch: 245 Train loss: 0.2207915700503758 Valid loss: 0.2702215465326463 Duration: 367.09066239595415 minutes\n",
      ", saved best model.\n",
      "Epoch: 246 Train loss: 0.21967946837203844 Valid loss: 0.2690962329506874 Duration: 368.5660163362821 minutes\n",
      ", saved best model.\n",
      "Epoch: 247 Train loss: 0.21854282049196108 Valid loss: 0.2845211679175977 Duration: 370.06474424203236 minutes\n",
      "Epoch: 248 Train loss: 0.21743669023258347 Valid loss: 0.2700113512335285 Duration: 371.5586521665255 minutes\n",
      "Epoch: 249 Train loss: 0.21579660687276295 Valid loss: 0.26901151107684257 Duration: 373.0358412106832 minutes\n",
      ", saved best model.\n",
      "Epoch: 250 Train loss: 0.21456621689881597 Valid loss: 0.266767538963787 Duration: 374.53072835206984 minutes\n",
      ", saved best model.\n",
      "Epoch: 251 Train loss: 0.21385956883856228 Valid loss: 0.2705009243180675 Duration: 376.01830683549247 minutes\n",
      "Epoch: 252 Train loss: 0.21236292755178043 Valid loss: 0.26643079230862277 Duration: 377.52358169953027 minutes\n",
      ", saved best model.\n",
      "Epoch: 253 Train loss: 0.21131480981622425 Valid loss: 0.2640987905042787 Duration: 379.01961127916974 minutes\n",
      ", saved best model.\n",
      "Epoch: 254 Train loss: 0.2108681000471115 Valid loss: 0.26348134875297546 Duration: 380.5246074875196 minutes\n",
      ", saved best model.\n",
      "Epoch: 255 Train loss: 0.2104470530152321 Valid loss: 0.262951799818585 Duration: 382.0317315061887 minutes\n",
      ", saved best model.\n",
      "Epoch: 256 Train loss: 0.2076400960598673 Valid loss: 0.2675599023219078 Duration: 383.5364084283511 minutes\n",
      "Epoch: 257 Train loss: 0.20831043757711137 Valid loss: 0.260294167024474 Duration: 385.0183041969935 minutes\n",
      ", saved best model.\n",
      "Epoch: 258 Train loss: 0.20810066809824534 Valid loss: 0.2591280219776015 Duration: 386.4789821426074 minutes\n",
      ", saved best model.\n",
      "Epoch: 259 Train loss: 0.20693993006859507 Valid loss: 0.2585884466046287 Duration: 387.98341080347694 minutes\n",
      ", saved best model.\n",
      "Epoch: 260 Train loss: 0.2039662488911833 Valid loss: 0.2538962248832949 Duration: 389.4832158962885 minutes\n",
      ", saved best model.\n",
      "Epoch: 261 Train loss: 0.20329880851932935 Valid loss: 0.2528906887577426 Duration: 390.9957629919052 minutes\n",
      ", saved best model.\n",
      "Epoch: 262 Train loss: 0.20144010254740716 Valid loss: 0.25741038723818715 Duration: 392.49128598769505 minutes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 263 Train loss: 0.20080649611779622 Valid loss: 0.25687064230442047 Duration: 393.94684640963874 minutes\n",
      "Epoch: 264 Train loss: 0.19913340354391507 Valid loss: 0.2477531341775771 Duration: 395.4045862555504 minutes\n",
      ", saved best model.\n",
      "Epoch: 265 Train loss: 0.19889218302709716 Valid loss: 0.24720956192862603 Duration: 396.90022894144056 minutes\n",
      ", saved best model.\n",
      "Epoch: 266 Train loss: 0.19720017644762994 Valid loss: 0.24762756641834013 Duration: 398.3910961906115 minutes\n",
      "Epoch: 267 Train loss: 0.1966570158238922 Valid loss: 0.24563330087450244 Duration: 399.8894765297572 minutes\n",
      ", saved best model.\n",
      "Epoch: 268 Train loss: 0.1956399308698518 Valid loss: 0.2463655235065568 Duration: 401.3858583251635 minutes\n",
      "Epoch: 269 Train loss: 0.19458618102754865 Valid loss: 0.2453583695234791 Duration: 402.89167675177254 minutes\n",
      ", saved best model.\n",
      "Epoch: 270 Train loss: 0.1937352590156453 Valid loss: 0.24260483862411591 Duration: 404.39323863188423 minutes\n",
      ", saved best model.\n",
      "Epoch: 271 Train loss: 0.19280073503085546 Valid loss: 0.2459322240564131 Duration: 405.8827137152354 minutes\n",
      "Epoch: 272 Train loss: 0.19185183969991548 Valid loss: 0.24399473566201427 Duration: 407.3672411719958 minutes\n",
      "Epoch: 273 Train loss: 0.19088320170555795 Valid loss: 0.2504360369376598 Duration: 408.8606674234072 minutes\n",
      "Epoch: 274 Train loss: 0.19006109791355474 Valid loss: 0.23836842671998085 Duration: 410.3645984093348 minutes\n",
      ", saved best model.\n",
      "Epoch: 275 Train loss: 0.1898733257140432 Valid loss: 0.23709122812555683 Duration: 411.852839076519 minutes\n",
      ", saved best model.\n",
      "Epoch: 276 Train loss: 0.18776480283481733 Valid loss: 0.2369673270131311 Duration: 413.3489041686058 minutes\n",
      ", saved best model.\n",
      "Epoch: 277 Train loss: 0.18705731219479016 Valid loss: 0.23967413303832855 Duration: 414.8417673746745 minutes\n",
      "Epoch: 278 Train loss: 0.18635696532045093 Valid loss: 0.2398608668196586 Duration: 416.32382697661717 minutes\n",
      "Epoch: 279 Train loss: 0.18513055758178235 Valid loss: 0.23540725438825547 Duration: 417.80590577920276 minutes\n",
      ", saved best model.\n",
      "Epoch: 280 Train loss: 0.18450185355118343 Valid loss: 0.23511934664941603 Duration: 419.324637901783 minutes\n",
      ", saved best model.\n",
      "Epoch: 281 Train loss: 0.18374007927094188 Valid loss: 0.23366974168006452 Duration: 420.8225558718046 minutes\n",
      ", saved best model.\n",
      "Epoch: 282 Train loss: 0.18258302954690797 Valid loss: 0.23154496137172945 Duration: 422.3060958663622 minutes\n",
      ", saved best model.\n",
      "Epoch: 283 Train loss: 0.18197561292563166 Valid loss: 0.23290547836692102 Duration: 423.7933125893275 minutes\n",
      "Epoch: 284 Train loss: 0.1806915967975344 Valid loss: 0.23224762250338832 Duration: 425.27905826568605 minutes\n",
      "Epoch: 285 Train loss: 0.18021722976863383 Valid loss: 0.23171954577968967 Duration: 426.7584126075109 minutes\n",
      "Epoch: 286 Train loss: 0.17910611127316953 Valid loss: 0.22837525870530836 Duration: 428.2622973839442 minutes\n",
      ", saved best model.\n",
      "Epoch: 287 Train loss: 0.17845526982205254 Valid loss: 0.23035447119224456 Duration: 429.745931216081 minutes\n",
      "Epoch: 288 Train loss: 0.17767468132930142 Valid loss: 0.22868839867653384 Duration: 431.24514373540876 minutes\n",
      "Epoch: 289 Train loss: 0.176451567911676 Valid loss: 0.22808815971497567 Duration: 432.748413225015 minutes\n",
      ", saved best model.\n",
      "Epoch: 290 Train loss: 0.17568973657063075 Valid loss: 0.2268166327548604 Duration: 434.23132177988685 minutes\n",
      ", saved best model.\n",
      "Epoch: 291 Train loss: 0.17503292605068002 Valid loss: 0.22582590339645262 Duration: 435.7375212709109 minutes\n",
      ", saved best model.\n",
      "Epoch: 292 Train loss: 0.1741030944458076 Valid loss: 0.22644987546147838 Duration: 437.23394588629407 minutes\n",
      "Epoch: 293 Train loss: 0.17330049423873425 Valid loss: 0.22395150285334356 Duration: 438.7318948070208 minutes\n",
      ", saved best model.\n",
      "Epoch: 294 Train loss: 0.17231624488745417 Valid loss: 0.22449552736455394 Duration: 440.2451424439748 minutes\n",
      "Epoch: 295 Train loss: 0.17177882062963076 Valid loss: 0.22364279753979174 Duration: 441.6727959513664 minutes\n",
      ", saved best model.\n",
      "Epoch: 296 Train loss: 0.1714498415333884 Valid loss: 0.22369729204764288 Duration: 443.17431307633717 minutes\n",
      "Epoch: 297 Train loss: 0.17110427499456066 Valid loss: 0.22303280961369315 Duration: 444.6372880578041 minutes\n",
      ", saved best model.\n",
      "Epoch: 298 Train loss: 0.17042202025013312 Valid loss: 0.2242175810519726 Duration: 446.1062290986379 minutes\n",
      "Epoch: 299 Train loss: 0.1693420412327562 Valid loss: 0.2208227684060412 Duration: 447.5830518960953 minutes\n",
      ", saved best model.\n",
      "Epoch: 300 Train loss: 0.16849736966192722 Valid loss: 0.21829211405448376 Duration: 449.07475715875626 minutes\n",
      ", saved best model.\n",
      "Epoch: 301 Train loss: 0.16789320341391223 Valid loss: 0.22096302654714353 Duration: 450.59418766101203 minutes\n",
      "Epoch: 302 Train loss: 0.16677144783096653 Valid loss: 0.21664388603981463 Duration: 452.0902345577876 minutes\n",
      ", saved best model.\n",
      "Epoch: 303 Train loss: 0.16624654264109476 Valid loss: 0.21515848691905698 Duration: 453.57415967384975 minutes\n",
      ", saved best model.\n",
      "Epoch: 304 Train loss: 0.16548534221947192 Valid loss: 0.21618355774591047 Duration: 455.0696220159531 minutes\n",
      "Epoch: 305 Train loss: 0.1653586442321539 Valid loss: 0.21297605918540108 Duration: 456.52359258731207 minutes\n",
      ", saved best model.\n",
      "Epoch: 306 Train loss: 0.16351106521912984 Valid loss: 0.21567910693345532 Duration: 458.0250061670939 minutes\n",
      "Epoch: 307 Train loss: 0.16268143271761282 Valid loss: 0.21208217511734656 Duration: 459.5237294197083 minutes\n",
      ", saved best model.\n",
      "Epoch: 308 Train loss: 0.16280626854726246 Valid loss: 0.21337993527131696 Duration: 461.01959460576376 minutes\n",
      "Epoch: 309 Train loss: 0.16141408265914237 Valid loss: 0.2132227908699743 Duration: 462.49793466726936 minutes\n",
      "Epoch: 310 Train loss: 0.16097478783556393 Valid loss: 0.21131932392956748 Duration: 463.9860054294268 minutes\n",
      ", saved best model.\n",
      "Epoch: 311 Train loss: 0.16015222071324076 Valid loss: 0.2110199177817952 Duration: 465.48561719655993 minutes\n",
      ", saved best model.\n",
      "Epoch: 312 Train loss: 0.16085559031367302 Valid loss: 0.20934465851995251 Duration: 466.9952117641767 minutes\n",
      ", saved best model.\n",
      "Epoch: 313 Train loss: 0.1588809609285423 Valid loss: 0.20926851929435808 Duration: 468.49567686716716 minutes\n",
      ", saved best model.\n",
      "Epoch: 314 Train loss: 0.15818190697048393 Valid loss: 0.2108859676387041 Duration: 469.9743459224701 minutes\n",
      "Epoch: 315 Train loss: 0.15717913683184556 Valid loss: 0.20631077975755738 Duration: 471.46974877913794 minutes\n",
      ", saved best model.\n",
      "Epoch: 316 Train loss: 0.15663391219079495 Valid loss: 0.2041335575162403 Duration: 472.9615407387416 minutes\n",
      ", saved best model.\n",
      "Epoch: 317 Train loss: 0.15601559507846832 Valid loss: 0.20719854257279827 Duration: 474.4629213372866 minutes\n",
      "Epoch: 318 Train loss: 0.15502264491149356 Valid loss: 0.2018780896380063 Duration: 475.95715037584307 minutes\n",
      ", saved best model.\n",
      "Epoch: 319 Train loss: 0.15432641554517407 Valid loss: 0.20485600793073255 Duration: 477.45314402977624 minutes\n",
      "Epoch: 320 Train loss: 0.15397409632908446 Valid loss: 0.2040464995248664 Duration: 478.9477724432945 minutes\n",
      "Epoch: 321 Train loss: 0.15257524047153337 Valid loss: 0.20565841773584967 Duration: 480.4461824973424 minutes\n",
      "Epoch: 322 Train loss: 0.15256677903447832 Valid loss: 0.20186264891057246 Duration: 481.9143172542254 minutes\n",
      ", saved best model.\n",
      "Epoch: 323 Train loss: 0.15164983353231634 Valid loss: 0.19927392503426922 Duration: 483.3946266015371 minutes\n",
      ", saved best model.\n",
      "Epoch: 324 Train loss: 0.15105413788131306 Valid loss: 0.20059620126360847 Duration: 484.89194707075757 minutes\n",
      "Epoch: 325 Train loss: 0.15050086996597903 Valid loss: 0.1993511392464561 Duration: 486.39050006866455 minutes\n",
      "Epoch: 326 Train loss: 0.1496387462743691 Valid loss: 0.19910136718423135 Duration: 487.8705142815908 minutes\n",
      ", saved best model.\n",
      "Epoch: 327 Train loss: 0.14901796569143022 Valid loss: 0.19571211898038465 Duration: 489.3102198322614 minutes\n",
      ", saved best model.\n",
      "Epoch: 328 Train loss: 0.14846748178984437 Valid loss: 0.19586489499816973 Duration: 490.79474030335746 minutes\n",
      "Epoch: 329 Train loss: 0.1473358445699726 Valid loss: 0.1950165491791502 Duration: 492.2473546862602 minutes\n",
      ", saved best model.\n",
      "Epoch: 330 Train loss: 0.146617134898901 Valid loss: 0.20030789401742718 Duration: 493.73742485841115 minutes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 331 Train loss: 0.14590332413784096 Valid loss: 0.19458567819768383 Duration: 495.22905847231544 minutes\n",
      ", saved best model.\n",
      "Epoch: 332 Train loss: 0.14547941101874623 Valid loss: 0.19727913686825382 Duration: 496.72575150330863 minutes\n",
      "Epoch: 333 Train loss: 0.1447943799772433 Valid loss: 0.19344086079828202 Duration: 498.23112214803695 minutes\n",
      ", saved best model.\n",
      "Epoch: 334 Train loss: 0.14427110324800013 Valid loss: 0.19504367818515148 Duration: 499.72946886618934 minutes\n",
      "Epoch: 335 Train loss: 0.14382646058712686 Valid loss: 0.19078317128362193 Duration: 501.2335102478663 minutes\n",
      ", saved best model.\n",
      "Epoch: 336 Train loss: 0.14287509240210056 Valid loss: 0.19950769312920108 Duration: 502.73219503561654 minutes\n",
      "Epoch: 337 Train loss: 0.14202245113466466 Valid loss: 0.19390439368303744 Duration: 504.2305729230245 minutes\n",
      "Epoch: 338 Train loss: 0.14175182256315436 Valid loss: 0.19005418556832498 Duration: 505.7311152299245 minutes\n",
      ", saved best model.\n",
      "Epoch: 339 Train loss: 0.14077674975139753 Valid loss: 0.18969285271821484 Duration: 507.2162624994914 minutes\n",
      ", saved best model.\n",
      "Epoch: 340 Train loss: 0.1402397778310946 Valid loss: 0.1979862625199941 Duration: 508.701434592406 minutes\n",
      "Epoch: 341 Train loss: 0.13964074294907705 Valid loss: 0.18931969910139038 Duration: 510.21553921699524 minutes\n",
      ", saved best model.\n",
      "Epoch: 342 Train loss: 0.13930874750230993 Valid loss: 0.19690898391267947 Duration: 511.7177112499873 minutes\n",
      "Epoch: 343 Train loss: 0.13842558109973158 Valid loss: 0.18389717249139662 Duration: 513.1981566150984 minutes\n",
      ", saved best model.\n",
      "Epoch: 344 Train loss: 0.1376668683311769 Valid loss: 0.1875327459626621 Duration: 514.6960753281911 minutes\n",
      "Epoch: 345 Train loss: 0.13718708530919893 Valid loss: 0.18361230266671028 Duration: 516.1655145645142 minutes\n",
      ", saved best model.\n",
      "Epoch: 346 Train loss: 0.1362040285893849 Valid loss: 0.18767523543248255 Duration: 517.6653805931409 minutes\n",
      "Epoch: 347 Train loss: 0.136153186204178 Valid loss: 0.1866856938408267 Duration: 519.1677914381028 minutes\n",
      "Epoch: 348 Train loss: 0.1354007624260017 Valid loss: 0.18756398732864088 Duration: 520.6701416055362 minutes\n",
      "Epoch: 349 Train loss: 0.13503928619197436 Valid loss: 0.180087003977068 Duration: 522.1709423700969 minutes\n",
      ", saved best model.\n",
      "Epoch: 350 Train loss: 0.134254925429821 Valid loss: 0.1803787431769794 Duration: 523.6216868321101 minutes\n",
      "Epoch: 351 Train loss: 0.13299799569589751 Valid loss: 0.1825506300214798 Duration: 525.0895418286324 minutes\n",
      "Epoch: 352 Train loss: 0.13298861635369913 Valid loss: 0.1836212318270437 Duration: 526.5945596853892 minutes\n",
      "Epoch: 353 Train loss: 0.13246332254792964 Valid loss: 0.1821132667002178 Duration: 528.0676349957783 minutes\n",
      "Epoch: 354 Train loss: 0.13179401887101785 Valid loss: 0.17945081289977796 Duration: 529.5767122069994 minutes\n",
      ", saved best model.\n",
      "Epoch: 355 Train loss: 0.1309955895968846 Valid loss: 0.17921839672471246 Duration: 531.0692925890287 minutes\n",
      ", saved best model.\n",
      "Epoch: 356 Train loss: 0.1304425244863544 Valid loss: 0.18241822503266797 Duration: 532.5630058010419 minutes\n",
      "Epoch: 357 Train loss: 0.12981575983762741 Valid loss: 0.17858209497024935 Duration: 534.0721135417621 minutes\n",
      ", saved best model.\n",
      "Epoch: 358 Train loss: 0.12932482058661324 Valid loss: 0.17966844327747822 Duration: 535.5402279337247 minutes\n",
      "Epoch: 359 Train loss: 0.1289870975443295 Valid loss: 0.177416191466393 Duration: 537.0288112839063 minutes\n",
      ", saved best model.\n",
      "Epoch: 360 Train loss: 0.12836694437052523 Valid loss: 0.1756231184568136 Duration: 538.534410115083 minutes\n",
      ", saved best model.\n",
      "Epoch: 361 Train loss: 0.1277385542584317 Valid loss: 0.1734521488749212 Duration: 540.0468733588855 minutes\n",
      ", saved best model.\n",
      "Epoch: 362 Train loss: 0.12733945241144726 Valid loss: 0.17607704255609744 Duration: 541.5474529822667 minutes\n",
      "Epoch: 363 Train loss: 0.12645026168652942 Valid loss: 0.17909356927679432 Duration: 543.0116842428844 minutes\n",
      "Epoch: 364 Train loss: 0.12607440237488066 Valid loss: 0.17509062107532256 Duration: 544.4864611506462 minutes\n",
      "Epoch: 365 Train loss: 0.12508698355725834 Valid loss: 0.17530280357647327 Duration: 545.9457665244738 minutes\n",
      "Epoch: 366 Train loss: 0.124867161114301 Valid loss: 0.1734394181760088 Duration: 547.4471960345904 minutes\n",
      ", saved best model.\n",
      "Epoch: 367 Train loss: 0.12389809169088091 Valid loss: 0.17243745814888709 Duration: 548.958681221803 minutes\n",
      ", saved best model.\n",
      "Epoch: 368 Train loss: 0.1239790140901293 Valid loss: 0.17044529414946033 Duration: 550.4188308437665 minutes\n",
      ", saved best model.\n",
      "Epoch: 369 Train loss: 0.12315786246742522 Valid loss: 0.17128287207695744 Duration: 551.9237632671992 minutes\n",
      "Epoch: 370 Train loss: 0.12246782357564995 Valid loss: 0.17822475010348904 Duration: 553.4166241168975 minutes\n",
      "Epoch: 371 Train loss: 0.12195332119613886 Valid loss: 0.16591836596208234 Duration: 554.8999029795328 minutes\n",
      ", saved best model.\n",
      "Epoch: 372 Train loss: 0.12114168980291912 Valid loss: 0.16910127291996632 Duration: 556.3957358797392 minutes\n",
      "Epoch: 373 Train loss: 0.12068088817170688 Valid loss: 0.1707843357637044 Duration: 557.896190349261 minutes\n",
      "Epoch: 374 Train loss: 0.12040978262041296 Valid loss: 0.16778717844957305 Duration: 559.3756163160007 minutes\n",
      "Epoch: 375 Train loss: 0.12025883673557214 Valid loss: 0.16867356098467304 Duration: 560.8750417470932 minutes\n",
      "Epoch: 376 Train loss: 0.11968563917704991 Valid loss: 0.16473731440642186 Duration: 562.3684698462487 minutes\n",
      ", saved best model.\n",
      "Epoch: 377 Train loss: 0.11877814882142203 Valid loss: 0.16623496642756846 Duration: 563.8594063599904 minutes\n",
      "Epoch: 378 Train loss: 0.11790915533474514 Valid loss: 0.16869301228753983 Duration: 565.3644579728444 minutes\n",
      "Epoch: 379 Train loss: 0.11763491081233536 Valid loss: 0.16650089206955127 Duration: 566.8472706357638 minutes\n",
      "Epoch: 380 Train loss: 0.11701397226963725 Valid loss: 0.16183276804945163 Duration: 568.2907484889031 minutes\n",
      ", saved best model.\n",
      "Epoch: 381 Train loss: 0.11653634257188865 Valid loss: 0.1634896112185332 Duration: 569.7933762351672 minutes\n",
      "Epoch: 382 Train loss: 0.11629514338288989 Valid loss: 0.1614162547573928 Duration: 571.2942369500796 minutes\n",
      ", saved best model.\n",
      "Epoch: 383 Train loss: 0.11579314853144544 Valid loss: 0.16701987049271982 Duration: 572.7910932977994 minutes\n",
      "Epoch: 384 Train loss: 0.11554398208537273 Valid loss: 0.16312281811429608 Duration: 574.2918048222859 minutes\n",
      "Epoch: 385 Train loss: 0.11457936482237918 Valid loss: 0.16329015665236982 Duration: 575.7966446518898 minutes\n",
      "Epoch: 386 Train loss: 0.11436862316408328 Valid loss: 0.16201443053902156 Duration: 577.2951726317406 minutes\n",
      "Epoch: 387 Train loss: 0.1135277532136866 Valid loss: 0.1611638959016531 Duration: 578.7799986640613 minutes\n",
      ", saved best model.\n",
      "Epoch: 388 Train loss: 0.1128757789720382 Valid loss: 0.1597149352272672 Duration: 580.2923640608788 minutes\n",
      ", saved best model.\n",
      "Epoch: 389 Train loss: 0.11207204560616187 Valid loss: 0.1626602762769307 Duration: 581.7878772258758 minutes\n",
      "Epoch: 390 Train loss: 0.11169079863812242 Valid loss: 0.16088393336582568 Duration: 583.2552269856135 minutes\n",
      "Epoch: 391 Train loss: 0.11132569779881409 Valid loss: 0.15712760911593515 Duration: 584.7392596761385 minutes\n",
      ", saved best model.\n",
      "Epoch: 392 Train loss: 0.11113868275071893 Valid loss: 0.15530436942654272 Duration: 586.210891187191 minutes\n",
      ", saved best model.\n",
      "Epoch: 393 Train loss: 0.11073013781330415 Valid loss: 0.1554640134976756 Duration: 587.6974923014641 minutes\n",
      "Epoch: 394 Train loss: 0.11002460835661207 Valid loss: 0.15898186217753157 Duration: 589.1667550166447 minutes\n",
      "Epoch: 395 Train loss: 0.1096078320347837 Valid loss: 0.15657043360894726 Duration: 590.6511995673179 minutes\n",
      "Epoch: 396 Train loss: 0.10883576846974237 Valid loss: 0.15749042063590982 Duration: 592.1569090485573 minutes\n",
      "Epoch: 397 Train loss: 0.10836292754326547 Valid loss: 0.15557537834730842 Duration: 593.6609764417012 minutes\n",
      "Epoch: 398 Train loss: 0.1079895179782595 Valid loss: 0.15604068492088588 Duration: 595.1193515936534 minutes\n",
      "Epoch: 399 Train loss: 0.10756271022558213 Valid loss: 0.15129516472018534 Duration: 596.593347076575 minutes\n",
      ", saved best model.\n",
      "Epoch: 400 Train loss: 0.10689930800242084 Valid loss: 0.1511483090298791 Duration: 598.0856542627017 minutes\n",
      ", saved best model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 401 Train loss: 0.10618273550271988 Valid loss: 0.15605718101705274 Duration: 599.5763759493827 minutes\n",
      "Epoch: 402 Train loss: 0.10578736566432885 Valid loss: 0.15279246118640707 Duration: 601.0417279084523 minutes\n",
      "Epoch: 403 Train loss: 0.1051981945027198 Valid loss: 0.15133381544822647 Duration: 602.5103176951409 minutes\n",
      "Epoch: 404 Train loss: 0.10471241310025964 Valid loss: 0.15068848968874063 Duration: 604.0039936741193 minutes\n",
      ", saved best model.\n",
      "Epoch: 405 Train loss: 0.10422975670014109 Valid loss: 0.14919370250596153 Duration: 605.4770634651184 minutes\n",
      ", saved best model.\n",
      "Epoch: 406 Train loss: 0.10392719157998051 Valid loss: 0.15234953531574819 Duration: 606.9761199990909 minutes\n",
      "Epoch: 407 Train loss: 0.1033229670396873 Valid loss: 0.14772393791786126 Duration: 608.4732955932617 minutes\n",
      ", saved best model.\n",
      "Epoch: 408 Train loss: 0.10281627149454185 Valid loss: 0.14934339004779054 Duration: 609.9594308972358 minutes\n",
      "Epoch: 409 Train loss: 0.10392021191758768 Valid loss: 0.1626486568261058 Duration: 611.456930788358 minutes\n",
      "Epoch: 410 Train loss: 0.11306419682502747 Valid loss: 0.15750932350995078 Duration: 612.9387867291769 minutes\n",
      "Epoch: 411 Train loss: 0.11044500318169594 Valid loss: 0.15633009830790182 Duration: 614.4217455744744 minutes\n",
      "Epoch: 412 Train loss: 0.10916352403908967 Valid loss: 0.15657035501733904 Duration: 615.8896357059479 minutes\n",
      "Epoch: 413 Train loss: 0.10809875060298613 Valid loss: 0.15282304551933082 Duration: 617.3926362276077 minutes\n",
      "Epoch: 414 Train loss: 0.10666434239063945 Valid loss: 0.15640805138935965 Duration: 618.895939497153 minutes\n",
      "Epoch: 415 Train loss: 0.10615985229079213 Valid loss: 0.15178860219255572 Duration: 620.3638284643491 minutes\n",
      "Epoch: 416 Train loss: 0.10524954135290214 Valid loss: 0.14782505121923262 Duration: 621.8572020610173 minutes\n",
      "Epoch: 417 Train loss: 0.1045719902898584 Valid loss: 0.14891229419698637 Duration: 623.3458912531535 minutes\n",
      "Epoch: 418 Train loss: 0.10379410825031145 Valid loss: 0.1526255475717687 Duration: 624.8386775096258 minutes\n",
      "Epoch: 419 Train loss: 0.10351950694301298 Valid loss: 0.14654425573685476 Duration: 626.3520745277405 minutes\n",
      ", saved best model.\n",
      "Epoch: 420 Train loss: 0.1025630698661719 Valid loss: 0.14545750786219874 Duration: 627.8580951730411 minutes\n",
      ", saved best model.\n",
      "Epoch: 421 Train loss: 0.10185537868844612 Valid loss: 0.14801443443303147 Duration: 629.3552561561266 minutes\n",
      "Epoch: 422 Train loss: 0.10189379897287913 Valid loss: 0.14543553423737327 Duration: 630.834460234642 minutes\n",
      ", saved best model.\n",
      "Epoch: 423 Train loss: 0.100857756351786 Valid loss: 0.14657467186090448 Duration: 632.3441188255946 minutes\n",
      "Epoch: 424 Train loss: 0.10034954823340689 Valid loss: 0.14569121950696554 Duration: 633.8340282718341 minutes\n",
      "Epoch: 425 Train loss: 0.0995438721052238 Valid loss: 0.14519303886880797 Duration: 635.3153717835744 minutes\n",
      ", saved best model.\n",
      "Epoch: 426 Train loss: 0.09904199949119773 Valid loss: 0.1405693398367974 Duration: 636.8194582819939 minutes\n",
      ", saved best model.\n",
      "Epoch: 427 Train loss: 0.09846606438606978 Valid loss: 0.14087421489098378 Duration: 638.3212189237277 minutes\n",
      "Epoch: 428 Train loss: 0.09789644854622227 Valid loss: 0.14559095091516933 Duration: 639.7975416382154 minutes\n",
      "Epoch: 429 Train loss: 0.09715515319577285 Valid loss: 0.14328531049672635 Duration: 641.2115578055382 minutes\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "patience = 2000\n",
    "\n",
    "patience_controler = Patience(patience)\n",
    "start_time = time.time()\n",
    "\n",
    "for num_epoch in range(5000000):\n",
    "    train_loss = train()        \n",
    "    valid_loss = validation()\n",
    "    \n",
    "    writer.add_scalar('Loss/train', train_loss, num_epoch)\n",
    "    writer.add_scalar('Loss/validation', valid_loss, num_epoch)\n",
    "    \n",
    "    print(f'Epoch: {num_epoch} Train loss: {train_loss} Valid loss: {valid_loss} Duration: {(time.time() - start_time)/60} minutes',)\n",
    "\n",
    "    if not patience_controler.more_patience(valid_loss):\n",
    "        print(\"Se acabó la paciencia\")\n",
    "        break\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.load_state_dict(torch.load('CNN_model_30000_words_TF_PAD_noise.pt'))\n",
    "CNN_model.eval()\n",
    "\n",
    "Encoder_model.load_state_dict(torch.load('Encoder_model_30000_words_TF_PAD_noise.pt'))\n",
    "Encoder_model.eval()\n",
    "\n",
    "Decoder_model.load_state_dict(torch.load('Decoder_model_30000_words_TF_PAD_noise.pt'))\n",
    "Decoder_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test():\n",
    "    with torch.no_grad():\n",
    "        for num_batch, (image_test, label_test) in enumerate(test_loader):\n",
    "            num_batch += 1\n",
    "            encoder_hidden_test = Encoder_model.initHidden(batch_size = batch_size)\n",
    "            image_cnn_test = image_test.view(-1, color_channels, patch_height, patch_width).cuda(0)\n",
    "            encoder_input_test = CNN_model(image_cnn_test)\n",
    "            encoder_output, encoder_hidden_test = Encoder_model(encoder_input_test, encoder_hidden_test, batch = test_batch, seq_len = n_patches)\n",
    "\n",
    "            #decoder_hidden_test = (encoder_hidden_test[0][0, :, :].view(1, batch_size, hidden_size), # We take the last hidden state of the Encoder \n",
    "            #                       encoder_hidden_test[1][0, :, :].view(1, batch_size, hidden_size)) # for each image/word (j) within the batch \n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                decoder_input_test = mapeo['START'].cuda(0) # We initialize the first Decoder input as the START token\n",
    "                decoder_hidden_test = (encoder_hidden_test[0][0, j, :].view(1, 1, hidden_size), # We take the last hidden state of the Encoder \n",
    "                                       encoder_hidden_test[1][0, j, :].view(1, 1, hidden_size)) # for each image/word (j) within the batch \n",
    "                \n",
    "                for d in range(MAX_LENGTH + 2):\n",
    "                    decoder_output_test, decoder_hidden_test = Decoder_model(decoder_input_test, decoder_hidden_test, batch = 1, seq_len = 1)\n",
    "\n",
    "                    output_letter = one_hot_conversion(decoder_output_test, output_size = output_size)\n",
    "                    decoder_input_test = output_letter\n",
    "                    \n",
    "                    if d == 0:\n",
    "                        output_word = output_letter\n",
    "                    else:\n",
    "                        output_word = torch.cat((output_word, output_letter), dim = 1).cuda(0)\n",
    "                    \n",
    "                    if torch.equal(output_letter, letter_to_vector('END').cuda(0)):\n",
    "                        break\n",
    "                output_word = torch.argmax(output_word, dim=2)\n",
    "                output_word = output_word.view(output_word.numel()) # view as a rank-1 tensor\n",
    "\n",
    "                model_word = []\n",
    "                for item in output_word:\n",
    "                    model_word.append(letters[item])\n",
    "\n",
    "                model_word = ''.join(model_word[:-1])\n",
    "                print(model_word)\n",
    "            print(test_set) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7b08819e076e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-c209519ca05f>\u001b[0m in \u001b[0;36mTest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnum_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mnum_batch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mencoder_hidden_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "list_random_strings = []\n",
    "import random \n",
    "import string\n",
    "batch_size = 256\n",
    "MAX_LENGTH = 15\n",
    "\n",
    "for i in range(batch_size):\n",
    "\n",
    "    list_random_strings.append(''.join(random.choice(string.ascii_lowercase) for _ in range(random.randint(1, MAX_LENGTH))))\n",
    "\n",
    "train_set = complete_set(list_random_strings)\n",
    "train_loader = DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "for b, (image, labels) in enumerate(train_loader):\n",
    "    print(b)\n",
    "\n",
    "    \n",
    "torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = (torch.ones(1,1, 256), torch.zeros(1,1,256))\n",
    "e_o = torch.ones(1, 15, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256])\n",
      "torch.Size([15, 256])\n",
      "torch.Size([1, 15, 256])\n"
     ]
    }
   ],
   "source": [
    "e_o = e_o.squeeze()\n",
    "fc_hidden = nn.Linear(256, 256, bias=False)\n",
    "fc_encoder = nn.Linear(256, 256, bias=False)\n",
    "\n",
    "c = fc_hidden(hidden[0]) + fc_encoder(e_o)\n",
    "print(fc_hidden(hidden[0]).shape)\n",
    "print(fc_encoder(e_o).shape)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activar pytorch_estoril (environment) en la terminal y ejecutar tensorboard --host 0.0.0.0 --logdir ./runs\n",
    "# Tensorboard se ejecutará en un cierto puerto y nos dará el enlace. Habrá que sustituir la IP 0.0.0.0 por la del equipo\n",
    "# en remoto en la que esté corriendo en el caso de Estoril 212.128.3.86:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_estoril",
   "language": "python",
   "name": "pytorch_estoril"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
