{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0892a649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "3.7.3\n"
     ]
    }
   ],
   "source": [
    "# Importing the recquired libraries:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Ignore harmless warnings:\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import platform\n",
    "print(torch.__version__)\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a04168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "['best', 'place', 'grow', 'answer', 'select', 'consonant', 'most', 'wave', 'red', 'hair', 'leave', 'love', 'street', 'finger', 'better']\n"
     ]
    }
   ],
   "source": [
    "top_1000_words = pd.read_csv('D:/Machine Learning/Pytorch/PYTORCH_NOTEBOOKS/PYTORCH_NOTEBOOKS/\\\n",
    "03-CNN-Convolutional-Neural-Networks/top_1000.txt', delimiter = '\\t', header = None)\n",
    "\n",
    "words = []\n",
    "\n",
    "for i in range(len(top_1000_words)):\n",
    "    for j in range(0, 10):\n",
    "        words.append(top_1000_words[0][i])\n",
    "        \n",
    "import random\n",
    "random.seed(101)\n",
    "random.shuffle(words)\n",
    "n = len(words)\n",
    "\n",
    "print(n)\n",
    "print(words[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439b89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and test sets:\n",
    "\n",
    "#train_set = words[0:800] # bajamos un orden de magnitud el training set\n",
    "#test_set = words[800:1000] # bajamos un orden de magnitud el test \n",
    "#len_train = len(train_set)\n",
    "#len_test = len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "006e4ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ['urjc', 'gavab'] * 400\n",
    "#train_set = words[0:32]*128\n",
    "#print(train_set[0:32])\n",
    "#import random\n",
    "#random.seed(101)\n",
    "#random.shuffle(train_set)\n",
    "len_train = len(train_set)\n",
    "\n",
    "#print(train_set[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08948f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# Function to convert letters (and therefore words) into PyTorch tensors:\n",
    "\n",
    "letters = ['SOS_token', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k',\n",
    "          'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'EOS_token']\n",
    "\n",
    "def letter_to_vector(letter):\n",
    "    vector = torch.zeros(1, 1, len(letters))\n",
    "    for i in range(len(letters)):\n",
    "        if letters[i] == letter:\n",
    "            vector[0, 0, i] = 1.\n",
    "    return(vector)\n",
    "\n",
    "print(letter_to_vector('SOS_token'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d81029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER:\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = input.view(1,1,-1)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f3a036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECODER:\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(output_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = input.view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b0ef9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss and optimization functions:\n",
    "\n",
    "torch.manual_seed(101)\n",
    "\n",
    "input_size = 28\n",
    "hidden_size = 256\n",
    "output_size = 28\n",
    "\n",
    "Encoder_model = EncoderRNN(input_size = input_size, hidden_size = hidden_size)\n",
    "Encoder_optimizer = optim.SGD(Encoder_model.parameters(), lr=0.01)\n",
    "\n",
    "Decoder_model = DecoderRNN(hidden_size = hidden_size, output_size = output_size)\n",
    "Decoder_optimizer = optim.SGD(Decoder_model.parameters(), lr=0.01)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa3f28b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a9ea01f3719b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mencoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mletter_to_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mencoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoder_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mletter_to_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SOS_token'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-701060e931a6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#embedded = self.embedding(input).view(1, 1, -1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             result = _impl(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[1;32m--> 211\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             result = _impl(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAINING THE MODEL:\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Setting the sliding window parameters:\n",
    "max_length = 20\n",
    "epochs = 25\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for j in range(len_train): # we chose individual words/images as batches:\n",
    "        \n",
    "        Encoder_optimizer.zero_grad()\n",
    "        Decoder_optimizer.zero_grad()\n",
    "        \n",
    "        input_word = list(train_set[j])\n",
    "        input_word_length = len(input_word) # number of letters\n",
    "        \n",
    "        encoder_hidden = Encoder_model.initHidden()\n",
    "        \n",
    "        \n",
    "        for l in range(input_word_length):\n",
    "            \n",
    "            encoder_input = letter_to_vector(input_word[l])\n",
    "            encoder_output, encoder_hidden = Encoder_model(encoder_input, encoder_hidden)\n",
    "            \n",
    "        decoder_input = letter_to_vector('SOS_token')\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        \n",
    "        for d in range(input_word_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden = Decoder_model(decoder_input, decoder_hidden)\n",
    "            #decoder_input = letter_to_vector(input_word[d])\n",
    "            \n",
    "            one_hot_decoder_output = torch.zeros(1, 1, output_size)\n",
    "            one_hot_decoder_output[0][0][torch.argmax(decoder_output)] = 1.\n",
    "            decoder_input = one_hot_decoder_output\n",
    "            \n",
    "            if torch.equal(one_hot_decoder_output, letter_to_vector('EOS_token'))==True:\n",
    "                break\n",
    "            \n",
    "            if d == 0:\n",
    "                \n",
    "                output_word = decoder_output \n",
    "                one_hot_input_word = letter_to_vector(input_word[d]).type(torch.LongTensor)\n",
    "                index = torch.argmax(one_hot_input_word.view(output_size))\n",
    "                ground_word = torch.tensor([index], dtype = torch.long)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                output_word = torch.cat((output_word, decoder_output), dim = 0) # we concatenate the remaining output letters\n",
    "                one_hot_input_word = torch.cat((one_hot_input_word,\n",
    "                                       letter_to_vector(input_word[d]).type(torch.LongTensor)), dim = 0)\n",
    "\n",
    "        \n",
    "        one_hot_input_word = one_hot_input_word.view(-1, output_size)\n",
    "        output_word = output_word.view(-1, output_size) \n",
    "        ground_word = torch.argmax(one_hot_input_word, dim = 1)\n",
    "        loss = criterion(output_word, ground_word)\n",
    "        \n",
    "        loss.backward()\n",
    "        Encoder_optimizer.step()\n",
    "        Decoder_optimizer.step()\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    print(i)\n",
    "print(train_losses)\n",
    "print(f'Duration: {(time.time() - start_time)/60} minutes')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c936ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Encoder_model.state_dict(), 'Encoder_model.pt')\n",
    "torch.save(Decoder_model.state_dict(), 'Decoder_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f1e4430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Losses per epoch E-D only-10 words')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8FHX+x/HXJ50kEEpCS0ILVekERUHAdmJBzq5nV1Q49c4rv5/nVX/XPM879Tx7xYpg7wVOEUSkiRSpAYGEFlpoIaR9f3/s4O3lSEggyWx5Px+PfWR3ZnbmMzubfc98p5lzDhERiT4xfhcgIiL+UACIiEQpBYCISJRSAIiIRCkFgIhIlFIAiIhEKQWAiMfMnJl19buO+mBmE8zsj37X0VjMbKSZFfhdR7hRAIQIM1trZqf5XYfUjpndaWZlZrY36FFUw/ATzKzUzPZ4jyVmdpeZpTVm3bVhZheb2RdmVmxm0w7Rv7+Zzff6zzez/j6UKfVAASC+M7NYv2s4QpOcc6lBj+aHGf6vzrmmQAZwLTAEmGlmKQ1ead3sAO4H/lK1h5klAG8BLwAtgGeBt7zujcLM4hprWpFOARAGzOwGM8szsx1m9raZtfe6m5ndZ2aFZrbLzBaZWW+v31lmttRb29xgZj8PGt85Zva1mRV5a3p9g/rd7g2/x8xWmNmp1dQ0wcweNbMp3rCfmVnHoP49vX47vPFcXOW9j5jZ+2a2Dzj5EONPM7OnzGyTV88fDwaFmV1jZjPN7J/efC8PrtPM2nuf0w7vc7shqF+smf3SzFZ7dc83s+ygSZ9mZqvMbKeZPWRmVreldXjOuRLn3FzgXKAVgTD4L2aWaGb3m9lG73G/mSV6/UaaWYGZ/cxb/pvMrLrxLDGz0UGv481sW3Vr7s65qc65ycDGQ/QeCcQB9zvnDjjnHgAMOOUQ0+3sfcdivNdPmllhUP8XzOw273lNy+xOM3vVG343cI2ZNfG+RzvNbCkwuMq0a/U9jnYKgBBnZqcAdwEXA+2AdcDLXu/vAcOB7kBz4BJgu9fvKeAmb42zN/CJN76BwNPATQR+fB4D3vZ+bHoAtwCDvfedAaytobzLgT8A6cDXwIveNFKAKcBLQGvgMuBhMzs26L0/AP4ENAU+P8S4nwXKga7AAG9exwb1Px5Y4037d8DrZtbS6zcRKADaAxcCfw76AfipV89ZQDPgOqA4aLznEPgx6UfgMz+jhvk/Ks65PQQ+p5OqGeRXBLYS+nv1HAf8Oqh/WyANyASuBx4ysxaHGM9zwBVBr88CNjnnvj6Cso8FFrn/vIbMIq/7f3DOfQvsJrD8IDCfe82sl/d6OPCZ97ymZQYwBniVwPf8RQLLPMd7nAFcfXDAI/geRy0FQOi7HHjaOfeVc+4AcAdwgpl1AsoI/ID2BMw5t8w5t8l7XxlwjJk1c87tdM595XW/AXjMOTfbOVfhnHsWOEDgh6YCSPTeF++cW+ucW11Dbe8556Z7df3KqyubwI/oWufcM865cm/arxH4xz7oLefcTOdcpXOuJHikZtYGOBO4zTm3zzlXCNwHXBo0WCGBtdAy59wkYAVwtjf9YcDt3pr218CTwJXe+8YCv3bOrXABC51z24PG+xfnXJFzbj3wKYEf3+pc7K3hHnx8WsOw1dkItKym3+XA751zhc65rcD/Bc0HBJbx773P4H1gL9DjEON5ATjLzJp5r68Enj+CWgFSgV1Vuu0i8D08lM+AEWbW1nv9qve6M4EAXliLZQYwyzn3pvd92U8gnP/knNvhnMsHHggatq7f46ilAAh97Qms9QPgnNtLYC0/0zn3CfAg8BCwxcweD/onv4DAmt46r3nmBK97R+BnwT9cQDbQ3jmXB9wG3AkUmtnL5jU3VSO/Sl07vHo7AsdXmcblBNZY/+u9h9ARiAc2Bb3/MQJbEwdtqLIWus6bdntgh7d2Hdwv03ueDdT0Y7A56HkxgR+86kx2zjUPepwM4DUxHdwx/GgN78era0c1/f5j2fPveTxou3Ou/HD1Ouc2AjOBC8ysOYFwPbi19mhQrb88TK0QCJlmVbo1A/YcYlgIBMBIAmv704FpwAjvMcM5V8nhlxn89/elfZVuwf8jdf0eRy0FQOjbSOAHEfiueaUVsAHAOfeAc24QgU3w7sD/eN3nOufGEPjRfBOY7I0in8CaU/APV7JzbqL3vpecc8O8aTrg7hpq+67t3MxSCazJbvSm8VmVaaQ658YHvbemy9DmE9gqSQ96fzPnXHAzQ2aV9vkO3rQ3Ai3NrGmVfhuCxp1Tw7SPmnPuz0E7hsdVN5z3mZ0GzKhmkP9Y9vx7Ho/EswSagS4isDZ98PszLqjWP9diPN8Afat89n297ofyGYGmn5He88+BoQQC4GDzz+GWGfz392UTQd8/b/h/D1y373HUUgCElngzSwp6xBFoR7/WAofeJQJ/BmY759aa2WAzO97M4oF9QAlQYWYJZna5maU558oItMNWeNN4Ahjnvc/MLMXMzjazpmbWw8xO8aZTAuwPet+hnGVmwyxwBMgfvLrygXeB7mZ2pbfDMd6rtVcN4/qO14z1MfB3M2tmZjFmlmNmI4IGaw38yBv3RUAv4H1v+l8Ad3mfYV8C7eMveu97EviDmXXz5r+vmbWqTV31xdvfMohAMO8Enqlm0InAr80sw8zSgd8SaM45Em8CA4EfE9gnUFN9sWaWRGBnb4z3OcZ7vacR+E78yJuPW7zunxxqXM65VQS+R1cA051zu4EtBLZQP/OGOdwyO5TJwB1m1sLMsoBbg+qv6/c4ejnn9AiBB4GdVK7K449ev3EEmi12EPhxzfK6n0pgB9xeYBuBf5hUIAH4kMCPy25gLjAsaFqjvG5FBNakXiHQhtsXmENgc/7gtNpXU+8E4FECOzH3Eti87xzUvwfwHrCVQJPVJ0D/oPf+8TCfRxrwCIEdg7uABcClXr9rCDRpPOj1Wwl8L+i9WV7tO7zPbVxQv1gCO1K/9eZzbtDn6YCuVebxkHUSaF4o8+Y9+NG6hs+r1JvmPgJrzHcDzWv4DJIItG1v8h4PAElev5FAwSG+Q6dVVzuB8NsHpB7ms7+G//4uTgjqPwCYT+CH9StgwGHGNxH4Nuj137zPIa6Wy+xO4IUq40wmEGRFwFICW74FXr9af4+j/WHeByZSJ2Y2gcA/3K8PN2wDTPsaYKwLbOJLLZnZb4HuzrkrDjuwRAWdUCESBbxDZK/nP4+skSinfQAiEc4CJ1XlAx8456b7XY+EDjUBiYhEKW0BiIhEqZDeB5Cenu46derkdxkiImFj/vz525xzGbUZNqQDoFOnTsybN8/vMkREwoaZrTv8UAFqAhIRiVIKABGRKKUAEBGJUgoAEZEoFZIBYGajzezxXbuqXnZcRETqS0gGgHPuHefcjWlpIXe/bBGRiBGSASAiIg0vIgPgmZnf8t6iTRwo1yXARUSqE9Ingh2JykrHS7PXs6pwLy2S4zlvQBaXDM6mR9vqblkqIhKdQvpicLm5ue5IzgSuqHR8nreNSXPXM2XpFsoqHP2zm3PJ4GxG92tPamLE5Z6ICABmNt85l1urYSMxAIJt33uANxZsYPK8fFZu2UuT+FjO6duOSwZnM6hjC/7z1qYiIuFNAXAIzjkW5BcxeW4+7yzcyL7SCnIyUrhkcDbnD8wiPTWxXqYjIuInBcBh7DtQznuLNjFpXj7z1+0kLsY4rVcbxo/MoV9283qfnohIY1EA1EFe4R4mzyvglXn57CwuY9Sxbfn5Gd3p2lo7jUUk/CgAjsDeA+U8NeNbnpixhuLSci4YmMVtp3cns3mTRpm+iEh9UAAchR37Snn40zye+3IdOLhiSEduPjmHVtpHICJhQAFQDzYW7ecfU1fxyvx8msTHMvakLow9qTNNk+J9qUdEpDYUAPUor3Av905ZwfuLN9MiOZ6bT+7KFUM6khQf62tdIiKHogBoAIsLdvHXj5YzY9U22qcl8ePTunHBwCxiY4zi0gqK9pexc18pRcVl7Cwupaj44PMyiopLA932lwHQNCmepklxNEuKCzxPjKPpwedBf5slxZOWHE9aE211iEjtKAAa0Bert/HXD1fwdX4RTRPjOFBeSWlFZbXDpyTE0jw5gRYp8TRvkoAZ7C4pZ09JGXu8vyVl1b8f4KoTOvKbc44hPjYiL90kIvWoLgGgayLU0Yk56bzxw1Z8vHQLn63cStOkOFokJ9AiOZ60JoG/LVISaO6tuSfGHb6pqLS8MigQAqFwMCQW5Bfx3Kx1LN+8h4cvH6gT1kSk3mgLIAy8uWADt7+2iFYpCTx2ZS59snSfBBE5tLpsAahNIQx8f0Amr447EYALH/2CNxds8LkiEYkECoAw0ScrjbdvHUa/7ObcNulr/vjuUspr2PcgInI4CoAwkp6ayItjj+eqEzry5Offcu2EuRQVl/pdloiEKQVAmImPjeH3Y3pz9wV9mL1mB+c+OJPlm3f7XZaIhCEFQJi6ZHAHJt44hJKyCs5/+As+WLzJ75JEJMwoAMLYoI4teOfWYfRo25TxL37F3z5aQWVl6B7VJSKhRQEQ5to0S+LlG4dwcW4WD36ax9jn5rG7pMzvskQkDCgAIkBiXCx3X9CXP4w5lukrt3LeQzMVAiJyWI0WAGaWYmbPmtkTZnZ5Y003WpgZV57QiQnXHse32/Zx9wfL/S5JRELcUQWAmT1tZoVmtqRK91FmtsLM8szsF17n84FXnXM3AOcezXSlesO6pXPd0M68OHs9X67Z7nc5IhLCjnYLYAIwKriDmcUCDwFnAscAl5nZMUAWkO8NVnGU05Ua/PR73enQMplfvLaIkjJ91CJyaEcVAM656cCOKp2PA/Kcc2ucc6XAy8AYoIBACNQ4XTO70czmmdm8rVu3Hk15USs5IY6/nN+HtduLuW/qSr/LEZEQ1RD7ADL595o+BH74M4HXgQvM7BHgnere7Jx73DmX65zLzcjIaIDyosOJXdO5dHA2T0xfw6KCIr/LEZEQ1BABYIfo5pxz+5xz1zrnxjvnXmyA6UoVd5zVi/TURP731UWU6bpBIlJFQwRAAZAd9DoL2NgA05HDSGsSzx++35vlm/fw2Ger/S5HREJMQwTAXKCbmXU2swTgUuDtuozAzEab2eO7du1qgPKiyxnHtuXsPu144F955BXu8bscEQkhR3sY6ERgFtDDzArM7HrnXDlwC/ARsAyY7Jz7pi7jdc6945y7MS1NNz6pD3eeeyxNEmK5/bXFulSEiHznaI8Cusw51845F++cy3LOPeV1f9851905l+Oc+1P9lCpHKqNpIr895xjmr9vJ81+u87scEQkRuhRElDh/YCbDu2dw94fLKdhZ7Hc5IhICFABRwsz483m9AfjlG0sI5XtBi0jjCMkA0E7ghpHVIpnbR/Vk+sqtvP6V7issEu1CMgC0E7jhXDmkI7kdW/D7d5eydc8Bv8sRER+FZABIw4mJMf5yQV/2l1Zw59t1OjhLRCKMAiAKdW2dyo9P68Z7izfx4ZLNfpcjIj5RAESpG4d3oVe7ZvzmrSXsKtbNY0SikQIgSsXHxnDPhX3Zsa+UP7+/zO9yRMQHIRkAOgqocfTOTOOGk7owaV4+n6/a5nc5ItLIQjIAdBRQ47nttG50SU/h2glz+O1bSyjcXeJ3SSLSSEIyAKTxJMXH8vKNQ7goN5uXZq9n+D2fcveHy7VfQCQKWCifEZqbm+vmzZvndxlRY+22fdw3dSVvL9xIamIc40bkcM2JnUhJjPO7NBGpJTOb75zLrdWwCgCpatmm3fz945VMXbaF9NQEbjm5K5cd34HEuFi/SxORw1AASL2Yv24n93y0nC/X7CCzeRNuO60b5w3IJC5WLYcioSrsA8DMRgOju3btesOqVav8LieqOef4PG8b93y0gkUFu8jJSOHn3+vBqN5tMTvU3T9FxE9hHwAHaQsgdDjn+Oibzfzt45XkFe6lT2Ya/7xsAJ3SU/wuTUSC1CUAtC0vtWJmjOrdjo9uG87fL+rH2m37uOsDnUAmEs4UAFInsTHGBYOyuHZoJz76ZovuMywSxhQAckSuGdqZJvGxPDJtjd+liMgRUgDIEWmZksBlx3Xgra836BaTImFKASBH7IbhnTGDJ6ZrK0AkHCkA5Ii1S2vCeQMyeXluPtv26u5iIuEmJANAVwMNHzeNyKG0opJnZn7rdykiUkchGQC6Gmj4yMlI5czebXlu1jp2l+gCciLhJCQDQMLLD0d2ZU9JOS98uc7vUkSkDhQActR6Z6YxvHsGT3/+LSVlFX6XIyK1pACQevHDkTls21vKK/Py/S5FRGpJASD14vjOLRnYoTmPTV9DWUWl3+WISC0oAKRemBk/HNmVgp37eWfhRr/LEZFaUABIvTmlZ2t6tm3KI9NWU1kZuleZFZEABYDUm5gYY/zIHFYV7mXqsi1+lyMihxGSAaATwcLX2X3a0aFlMg9NW00o32tCREI0AHQiWPiKi43hxuFdWJhfxKzV2/0uR0RqEJIBIOHtwkFZZDRN5OFpq/0uRURqoACQepcUH8vYYZ35PG8biwqK/C5HRKqhAJAGcfmQjjRLiuPhT7UVIBKqFADSIFIT47j6xE58+M1m3TZSJEQpAKTBXHNiJ5LiY3TbSJEQpQCQBtMqNZFLBwduG7mhaL/f5YhIFQoAaVA3Du8C6LaRIqFIASANqn3zwG0jJ85Zr9tGioQYBYA0uHEjddtIkVCkAJAGl5ORyqhjA7eNLNxd4nc5IuIJyQDQtYAiz09P7055hWPcC/M5UK67homEgpAMAF0LKPJ0a9OUey/ux1fri/j1G0t0oTiREBCSASCR6cw+7fjRqd14ZX4Bz8xc63c5IlFPASCN6rZTu3HGsW3443tLmbFqq9/liEQ1BYA0qpgY496L+9OtdVNueWkBa7ft87skkailAJBGl5IYxxNX5WIGY5+bx56SMr9LEolKCgDxRYdWyTz8g4F8u20fP5n0te4hLOIDBYD45sSu6fxu9DFMXVbI36es8LsckagT53cBEt2uHNKRZZt289Cnq+nZthmj+7X3uySRqKEtAPGVmfF/5/ZmcKcW/M+rC1myQSf/iTQWBYD4LiEuhkeuGETL5ARueG4eW/foonEijUEBICEhPTWRx6/KZWdxKeN1uQiRRqEAkJDROzONey7sx7x1O/ndW9/ochEiDUw7gSWkjO7XnhWb9/Dgp3n0ateMq0/s5HdJIhFLWwAScn56endO69WG37+7lJl52/wuRyRiKQAk5MTEGPdd0o+cjBSumzCX1+YX+F2SSERSAEhIapoUz0s3DGFAh+b87JWF/ObNJZSWV/pdlkhECckA0A1hBAJHBr1w/fHcOLwLz3+5jksfn8XmXbqjmEh9CckA0A1h5KC42Bh+eVYvHvrBQJZv3sM5/5zBl2u2+12WSEQIyQAQqersvu146+ahNGsSz+VPzubJGWt0mKjIUVIASNjo1qYpb908lNN7teGP7y3jlokL2Heg3O+yRMKWAkDCStOkeB65YiC3j+rJB4s38f2HZrJ6616/yxIJSwoACTtmxviROTx//fFs31fKmAdn8tE3m/0uSyTsKAAkbA3tms47tw4jJyOFm56fz18/XE6FbiwjUmsKAAlrmc2bMOmmE7jsuA48PG01Vz89hx37Sv0uSyQsKAAk7CXFx3LX+X346wV9mbN2B+c9PJM12i8gclgKAIkYFw/OZuINQ9hbUs55D3+h8wVEDkMBIBFlUMcWvPHDoaSnJnDlU7N5/StdR0ikOgoAiTgdWiXz+vihDO7Ukp9OXsi9U1bqpDGRQ1AASERKS45nwrXHcdGgLB741ypum/S17jImUoVuCCMRKyEuhr9e2JdO6Snc89EKNhbt57Erc2mZkuB3aSIhQVsAEtHMjJtP7so/LxvAwoJdnK8jhES+owCQqDC6X3sm3nA8u0vKOf+RL5itI4REFAASPQZ1bMmbPxxKq5QErtARQiIKAIkuB48Qyu0YOELoPh0hJFFMASBRJy05nmevO44LB2Xxj3+t4ieTvqasQreblOijo4AkKiXExXDPhX3p1CqZv328kvJKxz8uHUBsjPldmkijUQBI1DIzbjmlG3GxMfzlg+UkJ8Tyl/P7EqMQkCihAJCoN25EDsUHynngkzySE+L43ehjMFMISORTAIgAPzm9O3sPVPD0zG9JTYzj52f08LskkQanABAh0Bz0m3N6UVxazoOf5pGSGMf4kTl+lyXSoBQAIh4z40/n9aG4tIK7P1xOSmIsV53Qye+yRBqMAkAkSGyM8feL+1FcWsFv3/qG5IQ4LhyU5XdZIg2i0c4DMLMuZvaUmb3aWNMUORLxsTE8+IMBDOuazv++upD3F2/yuySRBlGrADCzp82s0MyWVOk+ysxWmFmemf2ipnE459Y4564/mmJFGktSfCyPXzWIgR1a8KOJC/h0eaHfJYnUu9puAUwARgV3MLNY4CHgTOAY4DIzO8bM+pjZu1Uereu1apFGkJwQx9PXDqZnu6aMe2E+s1brAnISWWoVAM656cCOKp2PA/K8NftS4GVgjHNusXPunCqPWq8+mdmNZjbPzOZt3bq11jMi0hCaJcXz3HXH06FlMmOfncuC9Tv9Lkmk3hzNPoBMID/odYHX7ZDMrJWZPQoMMLM7qhvOOfe4cy7XOZebkZFxFOWJ1I+WKQm8MPZ40psmcvXTc1i6cbffJYnUi6MJgEOdKlntZRWdc9udc+OccznOubuOYroija5NsyReHHs8KYlxXPnUbFbrpjISAY4mAAqA7KDXWcDGoytHJHRltUjmxbHHYwaXPDZLN5WRsHc0ATAX6GZmnc0sAbgUeLt+yhIJTV0yUnn5xhNolhTP5U/O5pmZ3+p+AhK2ansY6ERgFtDDzArM7HrnXDlwC/ARsAyY7Jz7pj6KMrPRZvb4rl276mN0IvWqa+tU3rxlKCN7ZPB/7yzlZ5MXUlJW4XdZInVmobz2kpub6+bNm+d3GSKHVFnp+Ocnedw3dSXHtm/Go1cMIrtlst9lSZQzs/nOudzaDKs7gokcoZgY48endeOpq3NZv6OYcx/8nJl52/wuS6TWFAAiR+nUXm14+5ZhpKcmcuVTs3nss9XaLyBhQQEgUg86p6fw5s1DGdW7LXd9sJxbJi6guLTc77JEahSSAaCdwBKOUhLjeOgHA7l9VE8+WLyJ8x76grXb9vldlki1QjIAnHPvOOduTEtL87sUkToxM8aPzGHCtcexeXcJ5z74OZ+u0IXkJDSFZACIhLvh3TN499ZhZLZI5roJc3nwk1VUVmq/gIQWBYBIA8lumczr409kTL/2/O3jlVz37FwK95T4XZbIdxQAIg2oSUIs913Sn9+POZZZq7cz6v4ZfPzNZr/LEgFCNAC0E1giiZlx1QmdePfWYbRtlsSNz8/njtcXse+AjhISf+lMYJFGVFpeyb1TVvLY9NV0bJnMfZf0Z0CHFn6XJRFEZwKLhKiEuBh+cWZPJt4whLIKx4WPzuIfU1dRXlHpd2kShRQAIj4Y0qUV7//4JEb3bcd9U1dy0WOzWLdd5wxI41IAiPgkrUk89186gH9c2p+8wr2c9Y8ZTJ6br8tISKNRAIj4bEz/TD68bTh9stL439cWMf6Fr9i5r9TvsiQKKABEQkBm8ya8NHYId5zZk38t38IZ90/ns5Vb/S5LIlxIBoAOA5VoFBNj3DQihzdvHkpak3iufnoO//PKQm0NSIPRYaAiIaikrIL7p67iiRlrSGsSz6/P7sV5AzIxM79LkxCnw0BFwlxSfCy/OLMn7946jI6tkvnp5IVc8dRsvtXVRaUeKQBEQlivds14bdyJ/OH7vVmUv4sz7p/Og5+sorRc5w3I0VMAiIS4mBjjyiEdmfqzEZzeqw1/+3glZz0wg7lrd/hdmoQ5BYBImGjTLImHLh/IU1fnsr+0gosencUdry9iV3GZ36VJmFIAiISZU3u1YcpPh3PDSZ2ZPK+AU++dxltfb9AJZFJnIRkAOgxUpGbJCXH86uxjeOvmoWQ2b8KPX/6aq5+Zy/rtxX6XJmFEh4GKhLmKSsfzs9Zyz0crKKt0jB3WmR+e3JXUxDi/SxMf6DBQkSgSG2NcM7Qz//rZSM7p046Hp61m5D3TmDR3PRW6DaXUQAEgEiHapiVx7yX9efPmoXRo2YTbX1vM6H9+zqzV2/0uTUKUAkAkwvTPbs5r40/kgcsGsGt/GZc98SXjnp+vy03Lf1EAiEQgM+Pcfu35189G8PPvdWf6qq2cfu907np/GbtLdNioBCgARCJYUnwst5zSjU9/PpIx/dvz+Iw1nHzPNF6cvU77B0QBIBIN2jRL4p6L+vH2zcPIyUjlV28s4ewHZjAzb5vfpYmPFAAiUaRPVhqTbhrCI5cPZF9pOZc/OZtrnpnD4gKdcxONFAAiUcbMOLNPO6b8ZAR3nNmTr/OLGP3g54x7fj4rNu/xuzxpRCF5IpiZjQZGd+3a9YZVq1b5XY5IRNtTUsbTn6/lyRlr2Ftazrn92nPbad3pnJ7id2lyBOpyIlhIBsBBOhNYpPEUFZfy+PQ1PDNzLaUVlVwwMJNbT+lGdstkv0uTOlAAiMgR27rnAI9MW80Ls9fhnOPSwR245ZSutGmW5HdpUgsKABE5apt27efBT/KYNDef2BjjqhM6Mm5EDq1SE/0uTWqgABCRepO/o5h//GsVr39VQFJ8LNcO7cT1w7rQMiXB79LkEBQAIlLvVm/dy/1TV/HOwo00iY/l0uOyGXtSFzKbN/G7NAmiABCRBrNqyx4em76GNxdsAODc/u0ZNyKH7m2a+lyZgAJARBrBhqL9PDXjWybOWc/+sgpO69WG8SNzGNSxhd+lRTUFgIg0mp37Snl21lomfLGWouIyjuvckvEjchjZIwMz87u8qKMAEJFGV1xazstz8nlixho27SqhZ9umjB+Zw9l92hEXq4sONBYFgIj4prS8krcXbuTRz1aTV7iX7JZNGDusCxcOyiJFt6lscAoAEfFdZaVj6rItPPLZahasL6JpYhwX5mZx1QmddJmJBhT2AaBrAYlEDuccC/KLePaLtby/eBNlFY6RPTK4+sROjOiWQUyM9hO2qdmGAAAHZUlEQVTUp7APgIO0BSASWQp3l/DSnPW8OHs9W/ccoHN6Cled0JELB2XRNCne7/IiggJAREJaaXklHyzZxIQv1rJgfREpCbFcMCjQPNS1darf5YU1BYCIhI1FBUVM+GIt7y7cRGlFJSd1S+fqEzpxcs/WxKp5qM4UACISdrbtPcDLc9bzwpfr2by7hMzmTbg4N5uLcrNor8tN1JoCQETCVllFJVOWbmHinPV87t2zeHi3DC4dnM2pvdqQEKdzCmqiABCRiJC/o5hX5hfwyrx8Nu0qoVVKAhcMyuLi3GztK6iGAkBEIkpFpWP6qq1MmpPP1GVbKK905HZswSWDszm7bzuSE3SC2UEKABGJWFv3HOD1rwqYNDefNdv2kZoYx7n923NJbjZ9s9Ki/vpDCgARiXjOOeat28nLc/J5b/FGSsoq6do6lfMGZHJuv/ZRey9jBYCIRJXdJWW8s3Ajby3YyJy1OwA4rlNLxgxoz9l92tE8OXruXqYAEJGolb+jmLcXbuSNBRvIK9xLfKxxco/WnDcgk5N7tiYpPtbvEhuUAkBEop5zjm827ubNBRt4a+FGtu45QNOkOM7u044x/TM5vnPLiLwOkQJARCRIRaXji9XbeGPBBj5aspl9pRW0T0tidP9AE1GfzMjZeawAEBGpxv7SCqYs28IbXxUwY9U2yisd2S2bcFbvdpzVp13YH0mkABARqYWi4lI+/mYL7y3exMy8QBhktWjCWX0CYdAvDMNAASAiUkdFxaVMWbqF9xdv4vO8bZRVODKbN+HM3m05q287BmQ3D4swCPsA0A1hRMRPu4rLmLIsEAYzVm2lrMLRPi2JM/u048zebRnQoUXIXqk07APgIG0BiIjfdu0vY+rSg2GwjdKKSlqlJHBqr9ac1qsNJ3XLoElC6BxaqgAQEWkAu0vKmLZiK1OXbuHTFYXsKSknKT6GYV0z+N4xbTilV2vSUxN9rbEuAaArKImI1FKzpHjO7deec/u1p7S8kjnf7mDK0s1MXVbI1GVbMIOBHVpw+jFtOP2YNuRkhPYVS7UFICJylJxzLN20mylLtzBl6Ra+2bgbgC7pKZx+TBtO7tmaQR1bEB/b8PcyUBOQiIiPNhbtZ+qyQBh8uWY7ZRWOpolxDOuWzsk9WjOiRwZtmiU1yLQVACIiIWJPSRkz87YzbUUh01ZsZfPuEgCOadeMkT0yOLlnawZkNyeunrYOFAAiIiHIOcfyzXuYtmIrn64oZP66nVRUOpolxXFStwxG9shgRI8MWjc98q0DBYCISBjYtb+MmXnbvts6KNxzAIDemc147rrjaZlS98tY6yggEZEwkNYk/rvLThzckTxtxVYWFRTRIjm+waevABARCQFmxrHt0zi2fVqjTbPhj0kSEZGQpAAQEYlSCgARkSilABARiVIKABGRKKUAEBGJUgoAEZEopQAQEYlSIX0pCDPbCqw7wrenA9vqsZxwEs3zDtE9/9E87xDd839w3js65zJq84aQDoCjYWbzans9jEgTzfMO0T3/0TzvEN3zfyTzriYgEZEopQAQEYlSkRwAj/tdgI+ied4huuc/mucdonv+6zzvEbsPQEREahbJWwAiIlIDBYCISJSKuAAws1FmtsLM8szsF37X09jMbK2ZLTazr80sou+naWZPm1mhmS0J6tbSzKaY2Srvbws/a2xI1cz/nWa2wVv+X5vZWX7W2FDMLNvMPjWzZWb2jZn92Ose8cu/hnmv87KPqH0AZhYLrAROBwqAucBlzrmlvhbWiMxsLZDrnIv4k2HMbDiwF3jOOdfb6/ZXYIdz7i/eCkAL59ztftbZUKqZ/zuBvc65v/lZW0Mzs3ZAO+fcV2bWFJgPfB+4hghf/jXM+8XUcdlH2hbAcUCec26Nc64UeBkY43NN0kCcc9OBHVU6jwGe9Z4/S+AfIyJVM/9RwTm3yTn3lfd8D7AMyCQKln8N815nkRYAmUB+0OsCjvCDCWMO+NjM5pvZjX4X44M2zrlNEPhHAVr7XI8fbjGzRV4TUcQ1gVRlZp2AAcBsomz5V5l3qOOyj7QAsEN0i5w2rtoZ6pwbCJwJ3Ow1E0j0eATIAfoDm4C/+1tOwzKzVOA14Dbn3G6/62lMh5j3Oi/7SAuAAiA76HUWsNGnWnzhnNvo/S0E3iDQLBZNtnhtpAfbSgt9rqdROee2OOcqnHOVwBNE8PI3s3gCP4AvOude9zpHxfI/1LwfybKPtACYC3Qzs85mlgBcCrztc02NxsxSvJ1CmFkK8D1gSc3vijhvA1d7z68G3vKxlkZ38MfPcx4RuvzNzICngGXOuXuDekX88q9u3o9k2UfUUUAA3qFP9wOxwNPOuT/5XFKjMbMuBNb6AeKAlyJ5/s1sIjCSwGVwtwC/A94EJgMdgPXARc65iNxRWs38jyTQBOCAtcBNB9vEI4mZDQNmAIuBSq/zLwm0hUf08q9h3i+jjss+4gJARERqJ9KagEREpJYUACIiUUoBICISpRQAIiJRSgEgIhKlFAAiIlFKASAiEqX+HzEzyV9DXHWMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting loss function:\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(train_losses)\n",
    "plt.title('Losses per epoch E-D only-10 words')\n",
    "#plt.savefig('E-D_only_800sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f79d20d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sesee\n"
     ]
    }
   ],
   "source": [
    "input_word_test = 'spent'\n",
    "\n",
    "with torch.no_grad():\n",
    "        \n",
    "    input_word_test = list(input_word_test)\n",
    "    input_word_test_length = len(input_word_test) # number of letters\n",
    "\n",
    "    encoder_hidden_test = Encoder_model.initHidden()\n",
    "\n",
    "\n",
    "    for l in range(input_word_test_length):\n",
    "\n",
    "        encoder_input_test = letter_to_vector(input_word_test[l])\n",
    "        _, encoder_hidden_test = Encoder_model(encoder_input_test, encoder_hidden_test)\n",
    "\n",
    "\n",
    "    decoder_input_test = letter_to_vector('SOS_token')\n",
    "    decoder_hidden_test = encoder_hidden_test\n",
    "\n",
    "\n",
    "    for d in range(input_word_test_length):\n",
    "\n",
    "        decoder_output_test, decoder_hidden_test = Decoder_model(decoder_input_test, decoder_hidden_test)\n",
    "        #decoder_input = letter_to_vector(input_word[d])\n",
    "\n",
    "        one_hot_decoder_output_test = torch.zeros(1, 1, output_size)\n",
    "        one_hot_decoder_output_test[0][0][torch.argmax(decoder_output_test)] = 1.\n",
    "        decoder_input_test = one_hot_decoder_output_test\n",
    "\n",
    "        if torch.equal(one_hot_decoder_output_test, letter_to_vector('EOS_token'))==True:\n",
    "            break\n",
    "\n",
    "        if d == 0:\n",
    "\n",
    "            output_word_test = decoder_output_test\n",
    "            one_hot_input_word_test = letter_to_vector(input_word_test[d]).type(torch.LongTensor)\n",
    "            index_test = torch.argmax(one_hot_input_word_test.view(output_size))\n",
    "            ground_word_test = torch.tensor([index_test], dtype = torch.long)\n",
    "\n",
    "        else:\n",
    "\n",
    "            output_word_test = torch.cat((output_word_test, decoder_output_test), dim = 0) \n",
    "            one_hot_input_word_test = torch.cat((one_hot_input_word_test,\n",
    "                                   letter_to_vector(input_word_test[d]).type(torch.LongTensor)), dim = 0)\n",
    "\n",
    "\n",
    "    one_hot_input_word_test = one_hot_input_word_test.view(-1, output_size)\n",
    "    output_word_test = output_word_test.view(-1, output_size) \n",
    "    ground_word_test = torch.argmax(one_hot_input_word_test, dim = 1)\n",
    "    \n",
    "    \n",
    "model_word = []\n",
    "\n",
    "indices = torch.argmax(output_word_test, dim = 1)\n",
    "\n",
    "for i in range(indices.numel()):\n",
    "    model_word.append(letters[indices[i]])\n",
    "\n",
    "model_word = ''.join(model_word)    \n",
    "print(model_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bec59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
