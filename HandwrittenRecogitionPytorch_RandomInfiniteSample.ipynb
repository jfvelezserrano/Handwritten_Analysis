{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66539e30",
   "metadata": {},
   "source": [
    "# Antes de empezar\n",
    "\n",
    "conda activate python3.6_cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b10b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "import cv2\n",
    "import skimage\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Ignore harmless warnings:\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea7ff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n",
      "3.6.10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 5000'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "print(torch.__version__)\n",
    "print(platform.python_version())\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86dd2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['START', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k',\n",
    "          'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'END', 'PAD']\n",
    "\n",
    "mapeo = {}\n",
    "\n",
    "cont = 0\n",
    "for key in letters:\n",
    "    vector = torch.zeros(1, 1, len(letters))\n",
    "    vector[0,0,cont] = 1.0\n",
    "    mapeo[key] = vector\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e63141c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapeo['START']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "453a76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_imagen(word):\n",
    "    image = 255 * np.ones(shape = (height, width), dtype = np.uint8)\n",
    "    image = cv2.putText(image, text = word, org = (5, 30),\n",
    "        fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.62, color = (0, 0, 0),\n",
    "        thickness = 1, lineType = cv2.LINE_AA)    \n",
    "    return image\n",
    "\n",
    "def patch_gen(num_batch, patches_tensor, word, n_patches, color_channels, patch_height, patch_width, stepsize):\n",
    "    image = crear_imagen(word)\n",
    "    #image = skimage.util.random_noise(image, mode='s&p')\n",
    "    image = 255 - image\n",
    "    image = transforms.ToPILImage()(image) # np.ndarray to PIL.Image.Image\n",
    "        \n",
    "    for p in range(n_patches):        \n",
    "        patch = transforms.functional.crop(image, 0, 0 + p * stepsize, patch_height, patch_width) # cropping of the image into patches\n",
    "        patch = transforms.ToTensor()(patch) # torch.Tensor of the patch (normalized)\n",
    "        #patch = torch.from_numpy(patch) # conversion to pytorch tensor again\n",
    "        patch = patch.view(1, 1, patch_height, patch_width) # CNN_model expects a 4-dimensional tensor (1 dimension for batch)\n",
    "        #patch = patch.type(torch.FloatTensor) # conversion to float\n",
    "        #patch = patch.cuda(0) # set to cuda\n",
    "        patches_tensor[num_batch, p, 0, :, :] = patch\n",
    " \n",
    "    return patches_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4e351a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 48\n",
    "width = 192\n",
    "patch_height = 48\n",
    "patch_width = 10\n",
    "stepsize = 2\n",
    "color_channels = 1\n",
    "batch_size=512\n",
    "MAX_LENGTH = 15\n",
    "n_patches = int((width - patch_width)/stepsize + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3690b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_set(word_set):    \n",
    "    patches_tensor = torch.empty(batch_size, n_patches, color_channels, patch_height, patch_width)\n",
    "    words = []\n",
    "    cont = 0\n",
    "    for word in word_set:\n",
    "        patch_gen(cont, patches_tensor, word, n_patches, color_channels, patch_height, patch_width, stepsize), \n",
    "        words.append(word)\n",
    "        cont += 1\n",
    "        \n",
    "    #patches_tensor = patches_tensor.cuda(0)        \n",
    "    return patches_tensor,words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c708c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_target(labels, seq_len, output_size,batch_size):    \n",
    "    one_hot_target = torch.empty(batch_size, seq_len, output_size) \n",
    "\n",
    "    for j,word in enumerate(labels):\n",
    "        length = len(word)\n",
    "        one_hot_target[j, 0, :] = mapeo['START']\n",
    "\n",
    "        for k,letter in enumerate(word):\n",
    "            one_hot_target[j, k + 1, :] = mapeo[letter]\n",
    "\n",
    "        one_hot_target[j, length + 1, :] = mapeo['END']\n",
    "        one_hot_target[j, length + 2: seq_len, :] = mapeo['PAD']\n",
    "        \n",
    "    return one_hot_target        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b2183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_conversion(decoder_output, output_size):\n",
    "    \n",
    "    one_hot_output_letter = torch.zeros(1, 1, output_size).cuda(0)\n",
    "    index = torch.argmax(decoder_output, dim = 2).item()\n",
    "    one_hot_output_letter[0, 0, index] = 1.\n",
    "    \n",
    "    return one_hot_output_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6bed8c",
   "metadata": {},
   "source": [
    "# Definiendo la arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54625c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTROS_EN_CNN_1 = 4\n",
    "NEURONS_IN_DENSE_LAYER = 1024\n",
    "PATCH_HEIGHT_AFTER_POOLING = patch_height//2\n",
    "PATCH_WIDTH_AFTER_POOLING = patch_width//2\n",
    "kernel_size = 1\n",
    "\n",
    "class ConvolutionalNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=FILTROS_EN_CNN_1, kernel_size=kernel_size, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(PATCH_HEIGHT_AFTER_POOLING*PATCH_WIDTH_AFTER_POOLING*FILTROS_EN_CNN_1, NEURONS_IN_DENSE_LAYER)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu((self.conv1(X)))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, PATCH_HEIGHT_AFTER_POOLING*PATCH_WIDTH_AFTER_POOLING*FILTROS_EN_CNN_1)\n",
    "        X = self.fc1(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a7997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first = True)\n",
    "\n",
    "    def forward(self, input, hidden, batch_size, seq_len):        \n",
    "        output = input.view(batch_size, seq_len, self.input_size)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(1, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aeaeda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm = nn.LSTM(output_size, hidden_size, batch_first = True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 2)\n",
    "        # dim = 2 porque esta última dimensión es la correspondiente a output_size, que es sobre\n",
    "        # la que queremos hacer el softmax\n",
    "\n",
    "    def forward(self, input, hidden, batch_size, seq_len):        \n",
    "        output = input.view(batch_size, seq_len, self.output_size)\n",
    "        #output = F.relu(output) # la relu se metía aquí porque en el\n",
    "        #caso NLP del ejemplo de PyTorch previamente había una capa de embedding\n",
    "        #No nos hace falta porque nuestro tensor de inputs ya es one-hot\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "               torch.zeros(1, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e93a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "encoder_input_size = 1024\n",
    "hidden_size = 256\n",
    "output_size = len(letters)\n",
    "\n",
    "CNN_model = ConvolutionalNetwork().cuda(0)\n",
    "CNN_optimizer = torch.optim.Adam(CNN_model.parameters())\n",
    "\n",
    "Encoder_model = EncoderRNN(input_size = encoder_input_size, hidden_size = hidden_size).cuda(0)\n",
    "Encoder_optimizer = optim.SGD(Encoder_model.parameters(), lr = 0.001)\n",
    "\n",
    "Decoder_model = DecoderRNN(hidden_size = hidden_size, output_size = output_size).cuda(0)\n",
    "Decoder_optimizer = optim.SGD(Decoder_model.parameters(), lr = 0.001)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46937e74",
   "metadata": {},
   "source": [
    "## Entrenando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e09123b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0527201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(decoder_output, ground_truth):\n",
    "    loss = 0\n",
    "        \n",
    "    for j in range(batch_size):\n",
    "        loss += criterion(decoder_output[j], ground_truth[j])               \n",
    "    \n",
    "    loss = loss/batch_size\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6782bd3-1f3a-44ad-b116-694357416995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genera_palabras_al_azar():\n",
    "    list_random_strings = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        list_random_strings.append(''.join(random.choice(string.ascii_lowercase) for _ in range(random.randint(1,MAX_LENGTH))))\n",
    "    return list_random_strings\n",
    "\n",
    "train_losses = []\n",
    "list_random_strings = genera_palabras_al_azar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a291fb31-a234-4a0b-bd1c-0b034f96f6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 2.2559378147125244\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "train_set = complete_set(list_random_strings)\n",
    "print(\"Tiempo:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f79be58-3321-436c-923a-9d5ceede7402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 92, 1, 48, 10])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_set, batch_size = batch_size)\n",
    "for b, (image, labels) in enumerate(train_loader):\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78fd1cbc-91bf-4f95-85df-143b3bdd2b83",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-2b6644c6a6c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_set[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b675fc48-73a0-4013-bbc9-7cff838c4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    train_losses = []\n",
    "    \n",
    "    for num_batch in range(0, 8):    \n",
    "        list_random_strings = genera_palabras_al_azar()\n",
    "        \n",
    "        image,labels = complete_set(list_random_strings)\n",
    "\n",
    "        encoder_hidden = Encoder_model.initHidden(batch_size)\n",
    "\n",
    "        image_cnn = image.view(-1, color_channels, patch_height, patch_width).cuda(0)\n",
    "        encoder_input = CNN_model(image_cnn)\n",
    "        encoder_output, encoder_hidden = Encoder_model(encoder_input, encoder_hidden, batch_size = batch_size, seq_len = n_patches)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = get_one_hot_target(labels=labels, batch_size = batch_size, seq_len = MAX_LENGTH + 2,output_size = output_size).cuda(0)\n",
    "        decoder_output, decoder_hidden = Decoder_model(decoder_input, decoder_hidden, batch_size = batch_size, seq_len = MAX_LENGTH + 2)\n",
    "\n",
    "        output_indices = torch.tensor(list(range(0, MAX_LENGTH + 2 -1))).cuda(0) # removing last token from the output\n",
    "        decoder_output = torch.index_select(decoder_output, dim = 1, index = output_indices)\n",
    "\n",
    "        ground_truth = torch.argmax(decoder_input, dim = 2)\n",
    "        target_indices = torch.tensor(list(range(1, MAX_LENGTH + 2))).cuda(0) # remove SOS token from the input\n",
    "        ground_truth = torch.index_select(ground_truth, dim = 1, index = target_indices)\n",
    "\n",
    "        loss = calculate_loss(decoder_output,ground_truth)\n",
    "\n",
    "        CNN_optimizer.zero_grad()\n",
    "        Encoder_optimizer.zero_grad()\n",
    "        Decoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        CNN_optimizer.step()\n",
    "        Encoder_optimizer.step()\n",
    "        Decoder_optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        print(num_batch,)\n",
    "            \n",
    "    return np.mean(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "24d30ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    \n",
    "    valid_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for num_batch in range(0, 2):\n",
    "            list_random_strings = genera_palabras_al_azar()        \n",
    "\n",
    "            image_val,label_val = complete_set(list_random_strings)\n",
    "\n",
    "            encoder_hidden_val = Encoder_model.initHidden(batch_size = batch_size)\n",
    "            image_cnn_val = image_val.view(-1, color_channels, patch_height, patch_width).cuda(0)\n",
    "            encoder_input_val = CNN_model(image_cnn_val)\n",
    "            encoder_output_val, encoder_hidden_val = Encoder_model(encoder_input_val, encoder_hidden_val, batch_size = batch_size, seq_len = n_patches)\n",
    "\n",
    "            decoder_hidden_val = encoder_hidden_val\n",
    "            decoder_input_val = get_one_hot_target(labels=label_val, batch_size = batch_size, seq_len = MAX_LENGTH + 2,output_size = output_size).cuda(0)\n",
    "            decoder_output_val, decoder_hidden_val = Decoder_model(decoder_input_val, decoder_hidden_val,batch_size = batch_size, seq_len = MAX_LENGTH + 2)\n",
    "\n",
    "            output_indices_val = torch.tensor(list(range(0, MAX_LENGTH + 1))).cuda(0) # remove last token from the output\n",
    "            decoder_output_val = torch.index_select(decoder_output_val, dim = 1, index = output_indices_val)\n",
    "\n",
    "            ground_truth_val = torch.argmax(decoder_input_val, dim = 2)\n",
    "            target_indices_val = torch.tensor(list(range(1, MAX_LENGTH + 2))).cuda(0) # remove START token from the input\n",
    "            ground_truth_val = torch.index_select(ground_truth_val, dim = 1, index = target_indices_val)\n",
    "\n",
    "            loss = calculate_loss(decoder_output_val,ground_truth_val)\n",
    "            valid_losses.append(loss.item())\n",
    "            print(num_batch,)\n",
    "                \n",
    "        return np.mean(valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b52e4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patience():\n",
    "    \n",
    "    def __init__(self, patience):\n",
    "        self.patience = patience\n",
    "        self.current_patience = patience\n",
    "        self.min_loss_val = float('inf')\n",
    "\n",
    "    def more_patience(self,loss_val):\n",
    "        self.current_patience -= 1\n",
    "        if self.current_patience == 0:\n",
    "            return False\n",
    "\n",
    "        if loss_val < self.min_loss_val:\n",
    "            self.min_loss_val = loss_val\n",
    "            self.current_patience = patience\n",
    "\n",
    "            model_name = f\"{height}x{width}_by{patch_width}_jump{stepsize}_batch{batch_size} NN_{FILTROS_EN_CNN_1}_{NEURONS_IN_DENSE_LAYER}_{kernel_size}_{hidden_size}_INFINITE_RANDOM_SAMPLE\"\n",
    "            print(\", saved best model.\")\n",
    "            \n",
    "            torch.save(CNN_model.state_dict(), 'CNN_'+model_name)\n",
    "            torch.save(Encoder_model.state_dict(), 'Encoder_'+model_name)\n",
    "            torch.save(Decoder_model.state_dict(), 'Decoder_'+model_name)\n",
    "    \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886fd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 0 Train loss: 3.2711853086948395 Valid loss: 3.268493413925171 Duration: 0.3914452433586121 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 1 Train loss: 3.257429838180542 Valid loss: 3.2457364797592163 Duration: 0.7825573166211446 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 2 Train loss: 3.2421314120292664 Valid loss: 3.2433758974075317 Duration: 1.172469707330068 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 3 Train loss: 3.2385210394859314 Valid loss: 3.2353293895721436 Duration: 1.5632980267206829 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 4 Train loss: 3.227178692817688 Valid loss: 3.2265758514404297 Duration: 1.9547272324562073 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 5 Train loss: 3.219053477048874 Valid loss: 3.212427020072937 Duration: 2.345786134401957 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 6 Train loss: 3.216281235218048 Valid loss: 3.217227339744568 Duration: 2.7377985239028932 minutes\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 7 Train loss: 3.2063241004943848 Valid loss: 3.203198194503784 Duration: 3.1291952888170878 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 8 Train loss: 3.1956694424152374 Valid loss: 3.2051886320114136 Duration: 3.5204510927200316 minutes\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 9 Train loss: 3.1990452110767365 Valid loss: 3.1891908645629883 Duration: 3.9113280614217123 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 10 Train loss: 3.1889392733573914 Valid loss: 3.190952181816101 Duration: 4.302744857470194 minutes\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 11 Train loss: 3.18475279211998 Valid loss: 3.1884056329727173 Duration: 4.693859306971232 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 12 Train loss: 3.1850927472114563 Valid loss: 3.179320812225342 Duration: 5.085010051727295 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 13 Train loss: 3.175119996070862 Valid loss: 3.173600912094116 Duration: 5.476396918296814 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 14 Train loss: 3.174637198448181 Valid loss: 3.167210340499878 Duration: 5.8676679293314615 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 15 Train loss: 3.1713898479938507 Valid loss: 3.165247917175293 Duration: 6.258552916844686 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 16 Train loss: 3.161623537540436 Valid loss: 3.1607390642166138 Duration: 6.649751579761505 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 17 Train loss: 3.1579302549362183 Valid loss: 3.1541329622268677 Duration: 7.040639440218608 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 18 Train loss: 3.159039556980133 Valid loss: 3.141111731529236 Duration: 7.432721157868703 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 19 Train loss: 3.148907631635666 Valid loss: 3.153975248336792 Duration: 7.823452019691468 minutes\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 20 Train loss: 3.138749361038208 Valid loss: 3.1378778219223022 Duration: 8.21325304110845 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 21 Train loss: 3.1413779258728027 Valid loss: 3.124991774559021 Duration: 8.6047598361969 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 22 Train loss: 3.13285830616951 Valid loss: 3.134384870529175 Duration: 8.995784298578899 minutes\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 23 Train loss: 3.1308010518550873 Valid loss: 3.128992795944214 Duration: 9.386260930697123 minutes\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 24 Train loss: 3.1269979774951935 Valid loss: 3.1235642433166504 Duration: 9.776940846443177 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 25 Train loss: 3.11713245511055 Valid loss: 3.116264224052429 Duration: 10.168798009554544 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 26 Train loss: 3.1229310631752014 Valid loss: 3.111047863960266 Duration: 10.560499366124471 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 27 Train loss: 3.1007584929466248 Valid loss: 3.117026448249817 Duration: 10.951405719916027 minutes\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 28 Train loss: 3.0990958213806152 Valid loss: 3.09909987449646 Duration: 11.341755843162536 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "0\n",
      "1\n",
      "Epoch: 29 Train loss: 3.10327684879303 Valid loss: 3.089528441429138 Duration: 11.73264053662618 minutes\n",
      ", saved best model.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "patience = 200\n",
    "patience_controler = Patience(patience)\n",
    "start_time = time.time()\n",
    "\n",
    "for num_epoch in range(500000):\n",
    "    train_loss = train()        \n",
    "    valid_loss = validation()\n",
    "    \n",
    "    writer.add_scalar('Loss/train', train_loss, num_epoch)\n",
    "    writer.add_scalar('Loss/validation', valid_loss, num_epoch)\n",
    "    \n",
    "    print(f'Epoch: {num_epoch} Train loss: {train_loss} Valid loss: {valid_loss} Duration: {(time.time() - start_time)/60} minutes',)\n",
    "\n",
    "    if not patience_controler.more_patience(valid_loss):\n",
    "        print(\"Se acabó la paciencia\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf79c2",
   "metadata": {},
   "source": [
    "## Cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.load_state_dict(torch.load('CNN_model_30000_words_TF_PAD_noise.pt'))\n",
    "CNN_model.eval()\n",
    "\n",
    "Encoder_model.load_state_dict(torch.load('Encoder_model_30000_words_TF_PAD_noise.pt'))\n",
    "Encoder_model.eval()\n",
    "\n",
    "Decoder_model.load_state_dict(torch.load('Decoder_model_30000_words_TF_PAD_noise.pt'))\n",
    "Decoder_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test():\n",
    "    with torch.no_grad():\n",
    "        for num_batch, (image_test, label_test) in enumerate(test_loader):\n",
    "            num_batch += 1\n",
    "            encoder_hidden_test = Encoder_model.initHidden(batch_size = batch_size)\n",
    "            image_cnn_test = image_test.view(-1, color_channels, patch_height, patch_width).cuda(0)\n",
    "            encoder_input_test = CNN_model(image_cnn_test)\n",
    "            encoder_output, encoder_hidden_test = Encoder_model(encoder_input_test, encoder_hidden_test, batch = test_batch, seq_len = n_patches)\n",
    "\n",
    "            #decoder_hidden_test = (encoder_hidden_test[0][0, :, :].view(1, batch_size, hidden_size), # We take the last hidden state of the Encoder \n",
    "            #                       encoder_hidden_test[1][0, :, :].view(1, batch_size, hidden_size)) # for each image/word (j) within the batch \n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                decoder_input_test = mapeo['START'].cuda(0) # We initialize the first Decoder input as the START token\n",
    "                decoder_hidden_test = (encoder_hidden_test[0][0, j, :].view(1, 1, hidden_size), # We take the last hidden state of the Encoder \n",
    "                                       encoder_hidden_test[1][0, j, :].view(1, 1, hidden_size)) # for each image/word (j) within the batch \n",
    "                \n",
    "                for d in range(MAX_LENGTH + 2):\n",
    "                    decoder_output_test, decoder_hidden_test = Decoder_model(decoder_input_test, decoder_hidden_test, batch = 1, seq_len = 1)\n",
    "\n",
    "                    output_letter = one_hot_conversion(decoder_output_test, output_size = output_size)\n",
    "                    decoder_input_test = output_letter\n",
    "                    \n",
    "                    if d == 0:\n",
    "                        output_word = output_letter\n",
    "                    else:\n",
    "                        output_word = torch.cat((output_word, output_letter), dim = 1).cuda(0)\n",
    "                    \n",
    "                    if torch.equal(output_letter, letter_to_vector('END').cuda(0)):\n",
    "                        break\n",
    "                output_word = torch.argmax(output_word, dim=2)\n",
    "                output_word = output_word.view(output_word.numel()) # view as a rank-1 tensor\n",
    "\n",
    "                model_word = []\n",
    "                for item in output_word:\n",
    "                    model_word.append(letters[item])\n",
    "\n",
    "                model_word = ''.join(model_word[:-1])\n",
    "                print(model_word)\n",
    "            print(test_set) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40956edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6_cv2",
   "language": "python",
   "name": "python3.6_cv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
