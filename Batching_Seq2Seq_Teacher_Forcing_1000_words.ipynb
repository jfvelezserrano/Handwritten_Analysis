{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "3.6.10\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "import cv2\n",
    "import skimage\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Ignore harmless warnings:\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import platform\n",
    "print(torch.__version__)\n",
    "print(platform.python_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TITAN X (Pascal)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1000_words = pd.read_csv('top_1000.txt', delimiter = '\\t', header = None)\n",
    "top_1000_words.head()\n",
    "words = []\n",
    "\n",
    "for i in range(0, len(top_1000_words)):\n",
    "    words.append(top_1000_words.loc[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "train_set = words * 32\n",
    "val_set = words * 2\n",
    "test_set = words[0:16]\n",
    "\n",
    "MAX_LENGTH = max(len(list(word)) for word in train_set)\n",
    "\n",
    "len_train = len(train_set)\n",
    "len_val = len(val_set)\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0.]]])\n",
      "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# Function to convert letters (and therefore words) into PyTorch tensors:\n",
    "\n",
    "letters = ['SOS_token', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k',\n",
    "          'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'EOS_token']\n",
    "\n",
    "PAD_token = torch.zeros(1, 1, 28)\n",
    "\n",
    "def letter_to_vector(letter):\n",
    "    vector = torch.zeros(1, 1, len(letters))\n",
    "    for i in range(len(letters)):\n",
    "        if letters[i] == letter:\n",
    "            vector[0, 0, i] = 1.\n",
    "    return(vector)\n",
    "\n",
    "print(PAD_token)\n",
    "print(letter_to_vector('SOS_token'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_gen(word, n_patches, patch_height, patch_width, stepsize):\n",
    "    \n",
    "    image = 255 * np.ones(shape = [height, width], dtype = np.uint8)\n",
    "    image = cv2.putText(image, text = word, org = (5, 30),\n",
    "    fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.7, color = (0, 0, 0),\n",
    "    thickness = 2, lineType = cv2.LINE_AA)\n",
    "    image = transforms.ToPILImage()(image) # np.ndarray to PIL.Image.Image\n",
    "    patches_tensor = torch.empty(n_patches, 1, patch_height, patch_width)\n",
    "    \n",
    "    for p in range(n_patches):\n",
    "        \n",
    "        patch = transforms.functional.crop(image, 0, 0 + p * stepsize, patch_height, patch_width) # cropping of the image into patches\n",
    "        patch = transforms.ToTensor()(patch) # torch.Tensor of the patch (normalized)\n",
    "        #patch = skimage.util.random_noise(patch, mode='gaussian') # we set some random noise to the image\n",
    "        #patch = torch.from_numpy(patch) # conversion to pytorch tensor again\n",
    "        patch = 1. - patch # it will work better if we have white text over black background\n",
    "        patch = patch.view(1, 1, patch_height, patch_width) # CNN_model expects a 4-dimensional tensor (1 dimension for batch)\n",
    "        patch = patch.type(torch.FloatTensor) # conversion to float\n",
    "        patch = patch.cuda(1) # set to cuda\n",
    "        patches_tensor[p, 0, :, :] = patch\n",
    "        patches_tensor = patches_tensor.cuda(1)\n",
    "        \n",
    "    return patches_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting image and sliding window parameters:\n",
    "\n",
    "height = 48\n",
    "width = 192\n",
    "patch_height = 48\n",
    "patch_width = 10\n",
    "stepsize = 2\n",
    "color_channels = 1\n",
    "n_patches = int((width - patch_width)/stepsize + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to get a tuple for each image with (its 92 tensor patches, label):\n",
    "\n",
    "def complete_set(set):\n",
    "    complete_set = []\n",
    "    for word in set:\n",
    "        complete_set.append((patch_gen(word, n_patches, patch_height, patch_width, stepsize), word))\n",
    "        \n",
    "    return complete_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_train_set = complete_set(set = train_set)\n",
    "comp_val_set = complete_set(set = val_set)\n",
    "comp_test_set = complete_set(set = test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 92, 1, 48, 10])\n",
      "torch.Size([1472, 1, 48, 10])\n",
      "('listen', 'control', 'mountain', 'event', 'space', 'sent', 'are', 'suggest', 'right', 'necessary', 'center', 'try', 'does', \"won't\", 'ago', 'path')\n"
     ]
    }
   ],
   "source": [
    "# Loading data in image batches:\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(comp_train_set, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(comp_val_set, batch_size = batch_size, shuffle=False)\n",
    "test_loader = DataLoader(comp_test_set, batch_size = batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "for image, label in train_loader:\n",
    "    break\n",
    "    \n",
    "image_cnn = image.view(-1, color_channels, patch_height, patch_width)   \n",
    "print(image.shape)\n",
    "print(image_cnn.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_target(label):\n",
    "    \n",
    "    one_hot_target = torch.zeros(batch_size, MAX_LENGTH + 1, output_size) # one_hot_tensor of the input batch of words for Decoder\n",
    "    \n",
    "    for j in range(batch_size): # for each word of the batch\n",
    "        \n",
    "        length = len(list(label[j])) # compute the number of letters\n",
    "        \n",
    "        one_hot_target[j, 0, :] = letter_to_vector('SOS_token') # the first letter of every word is always the SOS_token\n",
    "        \n",
    "        for k in range(length): # for each letter\n",
    "            \n",
    "            one_hot_target[j, k + 1, :] = letter_to_vector(list(label[j])[k]) # add the one_hot vector of that letter\n",
    "                                                                              # to the global tensor\n",
    "    return one_hot_target        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model and architecture:\n",
    "\n",
    "# CONVOLUTIONAL NEURAL NETWORK:\n",
    "\n",
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1, 2) # padding???\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1, 2)\n",
    "        self.fc1 = nn.Linear(12*2*50, 1024)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 12*2*50) # -1 para no tener que determinar aquí el tamaño del batch (se ajusta, podemos variarlo)\n",
    "        X = F.relu(self.fc1(X))\n",
    "\n",
    "        return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER:\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first = True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        output = input.view(batch_size, n_patches, input_size)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(1, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECODER:\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(output_size, hidden_size, batch_first = True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 2) \n",
    "        # dim = 2 porque esta última dimensión es la correspondiente a output_size, que es sobre\n",
    "        # la que queremos hacer el softmax\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #output = input.view(batch_size, MAX_LENGTH + 1, output_size)\n",
    "        output = input\n",
    "        #output = F.relu(output) # la relu se metía aquí porque en el\n",
    "        #caso NLP del ejemplo de PyTorch previamente había una capa de embedding\n",
    "        #No nos hace falta porque nuestro tensor de inputs ya es one-hot\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "               torch.zeros(1, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_size = 1024\n",
    "hidden_size = 256\n",
    "output_size = 28\n",
    "\n",
    "CNN_model = ConvolutionalNetwork().cuda(1)\n",
    "CNN_optimizer = torch.optim.Adam(CNN_model.parameters(), lr = 0.001)\n",
    "\n",
    "Encoder_model = EncoderRNN(input_size = input_size, hidden_size = hidden_size).cuda(1)\n",
    "Encoder_optimizer = optim.SGD(Encoder_model.parameters(), lr = 0.001)\n",
    "\n",
    "Decoder_model = DecoderRNN(hidden_size = hidden_size, output_size = output_size).cuda(1)\n",
    "Decoder_optimizer = optim.SGD(Decoder_model.parameters(), lr = 0.001)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "Duration: 58.903458992640175 minutes\n",
      "[tensor(0.5930, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.7658, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.8007, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.6637, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5816, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.6378, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.6266, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.6782, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.6255, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5854, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.6708, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5108, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.6943, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4955, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.6373, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5240, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5674, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4932, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5297, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4293, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3835, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.6040, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4836, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4674, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.6295, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5266, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5468, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4649, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5210, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5918, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4186, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4958, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4355, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3765, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3938, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2642, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2621, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4870, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3968, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4287, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3998, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3652, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5405, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.4707, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2640, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2640, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3351, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3099, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3129, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3021, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3471, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2796, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3227, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.5076, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3053, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3269, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3514, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2745, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3189, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2785, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2307, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2992, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3211, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2614, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3753, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.3309, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2664, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2199, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2511, device='cuda:1', grad_fn=<DivBackward0>), tensor(0.2398, device='cuda:1', grad_fn=<DivBackward0>)]\n",
      "[tensor(0.8131, device='cuda:1'), tensor(0.7876, device='cuda:1'), tensor(0.7733, device='cuda:1'), tensor(0.7702, device='cuda:1'), tensor(0.7576, device='cuda:1'), tensor(0.7414, device='cuda:1'), tensor(0.7227, device='cuda:1'), tensor(0.7134, device='cuda:1'), tensor(0.7094, device='cuda:1'), tensor(0.6919, device='cuda:1'), tensor(0.6867, device='cuda:1'), tensor(0.6716, device='cuda:1'), tensor(0.6683, device='cuda:1'), tensor(0.6541, device='cuda:1'), tensor(0.6493, device='cuda:1'), tensor(0.6398, device='cuda:1'), tensor(0.6361, device='cuda:1'), tensor(0.6248, device='cuda:1'), tensor(0.6216, device='cuda:1'), tensor(0.6090, device='cuda:1'), tensor(0.6034, device='cuda:1'), tensor(0.5917, device='cuda:1'), tensor(0.5841, device='cuda:1'), tensor(0.5844, device='cuda:1'), tensor(0.5798, device='cuda:1'), tensor(0.5657, device='cuda:1'), tensor(0.5612, device='cuda:1'), tensor(0.5522, device='cuda:1'), tensor(0.5554, device='cuda:1'), tensor(0.5415, device='cuda:1'), tensor(0.5337, device='cuda:1'), tensor(0.5333, device='cuda:1'), tensor(0.5219, device='cuda:1'), tensor(0.5143, device='cuda:1'), tensor(0.5124, device='cuda:1'), tensor(0.5020, device='cuda:1'), tensor(0.4988, device='cuda:1'), tensor(0.5017, device='cuda:1'), tensor(0.4903, device='cuda:1'), tensor(0.4931, device='cuda:1'), tensor(0.4809, device='cuda:1'), tensor(0.4684, device='cuda:1'), tensor(0.4689, device='cuda:1'), tensor(0.4690, device='cuda:1'), tensor(0.4563, device='cuda:1'), tensor(0.4580, device='cuda:1'), tensor(0.4486, device='cuda:1'), tensor(0.4587, device='cuda:1'), tensor(0.4349, device='cuda:1'), tensor(0.4326, device='cuda:1'), tensor(0.4295, device='cuda:1'), tensor(0.4378, device='cuda:1'), tensor(0.4256, device='cuda:1'), tensor(0.4140, device='cuda:1'), tensor(0.4125, device='cuda:1'), tensor(0.4014, device='cuda:1'), tensor(0.4022, device='cuda:1'), tensor(0.3961, device='cuda:1'), tensor(0.3907, device='cuda:1'), tensor(0.3896, device='cuda:1'), tensor(0.3858, device='cuda:1'), tensor(0.3914, device='cuda:1'), tensor(0.3786, device='cuda:1'), tensor(0.3713, device='cuda:1'), tensor(0.3777, device='cuda:1'), tensor(0.3622, device='cuda:1'), tensor(0.3696, device='cuda:1'), tensor(0.3588, device='cuda:1'), tensor(0.3592, device='cuda:1'), tensor(0.3487, device='cuda:1')]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING THE MODEL:\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 70\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for b, (image, label) in enumerate(train_loader):\n",
    "        \n",
    "        b += 1\n",
    "        \n",
    "        encoder_hidden = Encoder_model.initHidden()\n",
    "        \n",
    "        image_cnn = image.view(-1, color_channels, patch_height, patch_width).cuda(1)\n",
    "        encoder_input = CNN_model(image_cnn)\n",
    "        _, encoder_hidden = Encoder_model(encoder_input, encoder_hidden)\n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = get_one_hot_target(label=label).cuda(1)\n",
    "        decoder_output, decoder_hidden = Decoder_model(decoder_input, decoder_hidden)\n",
    "        \n",
    "        output_indices = torch.tensor(list(range(0, MAX_LENGTH))).cuda(1) # remove EOS_token from the output\n",
    "        decoder_output = torch.index_select(decoder_output, dim = 1, index = output_indices)\n",
    "        \n",
    "        ground_truth = torch.argmax(decoder_input, 2)\n",
    "        target_indices = torch.tensor(list(range(1, MAX_LENGTH + 1))).cuda(1) # remove SOS_token from the input\n",
    "        ground_truth = torch.index_select(ground_truth, dim = 1, index = target_indices)\n",
    "        #decoder_output = decoder_output.view(batch_size, output_size, MAX_LENGTH)\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        for j in range(batch_size):\n",
    "            \n",
    "            loss += criterion(decoder_output[j], ground_truth[j])   \n",
    "        #loss = criterion(decoder_output[j], ground_truth[j]) + criterion(decoder_output[1], ground_truth[1])\n",
    "        \n",
    "        loss = loss/batch_size\n",
    "        \n",
    "        CNN_optimizer.zero_grad()\n",
    "        Encoder_optimizer.zero_grad()\n",
    "        Decoder_optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        CNN_optimizer.step()\n",
    "        Encoder_optimizer.step()\n",
    "        Decoder_optimizer.step()\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for v, (image_val, label_val) in enumerate(val_loader):\n",
    "        \n",
    "            v += 1\n",
    "\n",
    "            encoder_hidden_val = Encoder_model.initHidden()\n",
    "\n",
    "            image_cnn_val = image_val.view(-1, color_channels, patch_height, patch_width).cuda(1)\n",
    "            encoder_input_val = CNN_model(image_cnn_val)\n",
    "            _, encoder_hidden_val = Encoder_model(encoder_input_val, encoder_hidden_val)\n",
    "\n",
    "            decoder_hidden_val = encoder_hidden_val\n",
    "            decoder_input_val = get_one_hot_target(label=label_val).cuda(1)\n",
    "            decoder_output_val, decoder_hidden_val = Decoder_model(decoder_input_val, decoder_hidden_val)\n",
    "\n",
    "            output_indices_val = torch.tensor(list(range(0, MAX_LENGTH))).cuda(1) # remove EOS_token from the output\n",
    "            decoder_output_val = torch.index_select(decoder_output_val, dim = 1, index = output_indices_val)\n",
    "\n",
    "            ground_truth_val = torch.argmax(decoder_input_val, 2)\n",
    "            target_indices_val = torch.tensor(list(range(1, MAX_LENGTH + 1))).cuda(1) # remove SOS_token from the input\n",
    "            ground_truth_val = torch.index_select(ground_truth_val, dim = 1, index = target_indices_val)\n",
    "            #decoder_output_val = decoder_output_val.view(batch_size, output_size, MAX_LENGTH)\n",
    "            \n",
    "            loss_val = 0\n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                \n",
    "                loss_val += criterion(decoder_output_val[j], ground_truth_val[j])\n",
    "            \n",
    "            #loss_val = criterion(decoder_output_val[0], ground_truth_val[0]) + criterion(decoder_output_val[1], ground_truth_val[1])\n",
    "            loss_val = loss_val/batch_size\n",
    "        \n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    val_losses.append(loss_val)\n",
    "    print(i)\n",
    "    \n",
    "print(f'Duration: {(time.time() - start_time)/60} minutes')    \n",
    "print(train_losses)\n",
    "print(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting results\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.title('Losses per epoch CNN-S2S 1000 words')\n",
    "plt.legend();\n",
    "#plt.savefig('8 words training losses lr=0,001, bs=2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(CNN_model.state_dict(), 'CNN_model_8_words_batch.pt')\n",
    "#torch.save(Encoder_model.state_dict(), 'Encoder_model_8_words_batch.pt')\n",
    "#torch.save(Decoder_model.state_dict(), 'Decoder_model_8_words_batch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'of', 'to', 'and', 'a', 'in', 'is', 'it', 'you', 'that', 'he', 'was', 'for', 'on', 'are', 'with')\n",
      "tensor([[20,  8,  5,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [15,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [20, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 14,  4,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [25, 15, 21,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [20,  8,  1, 20,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 8,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [23,  1, 19,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6, 15, 18,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [15, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 18,  5,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [23,  9, 20,  8,  0,  0,  0,  0,  0,  0,  0]], device='cuda:1')\n",
      "the\n",
      "of\n",
      "to\n",
      "and\n",
      "a\n",
      "in\n",
      "is\n",
      "it\n",
      "you\n",
      "that\n",
      "he\n",
      "was\n",
      "for\n",
      "on\n",
      "are\n",
      "with\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        \n",
    "    for t, (image_test, label_test) in enumerate(test_loader):\n",
    "\n",
    "        t += 1\n",
    "\n",
    "        encoder_hidden_test = Encoder_model.initHidden()\n",
    "        image_cnn_test = image_test.view(-1, color_channels, patch_height, patch_width).cuda(1)\n",
    "        encoder_input_test = CNN_model(image_cnn_test)\n",
    "        encoder_outputs_test, encoder_hidden_test = Encoder_model(encoder_input_test, encoder_hidden_test)\n",
    "        print(label_test)\n",
    "        for j in range(batch_size):\n",
    "           \n",
    "            decoder_input_test = letter_to_vector('SOS_token').cuda(1) # We initialize the first Decoder input as the SOS token\n",
    "            \n",
    "            decoder_hidden_test = (encoder_hidden_test[0][0, j, :].view(1, 1, hidden_size), # We take the last hidden state of the Encoder \n",
    "                                   encoder_hidden_test[1][0, j, :].view(1, 1, hidden_size)) # for each image/word (j) within the patch \n",
    "            # This would be the first hidden state of the Decoder for image/word (j)\n",
    "\n",
    "            for d in range(MAX_LENGTH):\n",
    "                \n",
    "                decoder_output_test, decoder_hidden_test = Decoder_model(decoder_input_test, decoder_hidden_test)\n",
    "                \n",
    "                if d == 0:\n",
    "                    \n",
    "                    output_word = decoder_output_test\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    output_word = torch.cat((output_word, decoder_output_test), dim = 1).cuda(1)\n",
    "                    \n",
    "            output_word = torch.argmax(output_word, dim = 2)\n",
    "            \n",
    "            \n",
    "            if j == 0:\n",
    "                \n",
    "                total_output_word = output_word\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                total_output_word = torch.cat((total_output_word, output_word), dim = 0)\n",
    "           \n",
    "    print(total_output_word)\n",
    "\n",
    "\n",
    "for j in range(batch_size):\n",
    "    \n",
    "    model_word = []\n",
    "    \n",
    "    for i in range(total_output_word[j].numel()):\n",
    "        \n",
    "        if letters[total_output_word[j][i]] == 'SOS_token':\n",
    "            break\n",
    "            \n",
    "        model_word.append(letters[total_output_word[j][i]])\n",
    "        \n",
    "        \n",
    "    model_word = ''.join(model_word)    \n",
    "    print(model_word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.2407, -0.3303, -1.2581],\n",
      "         [-0.1125, -1.2684, -0.3344]]])\n",
      "tensor([[[-1.3905, -0.8152, -0.3204],\n",
      "         [ 0.7377, -1.7534,  0.6033]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(101)\n",
    "c = nn.LogSoftmax(dim=1)\n",
    "a = torch.randn(1,2,3)\n",
    "print(c(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7392961570497802"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log((np.exp(-1.3905))/(np.exp(-1.3905) + np.exp(-0.8152) + np.exp(-0.3204)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.240681356437162"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log((np.exp(-1.3905))/(np.exp(-1.3905) + np.exp(0.7377)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:1')\n",
      "tensor(0, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(28).cuda(1)\n",
    "c = torch.argmax(a, dim = 0)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/pytorch_estoril/lib/python3.6/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6f773bcc8c52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch_estoril/lib/python3.6/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     raise ImportError('TensorBoard logging requires TensorBoard with Python summary writer installed. '\n\u001b[0m\u001b[1;32m      5\u001b[0m                       'This should be available in 1.14 or above.')\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_estoril",
   "language": "python",
   "name": "pytorch_estoril"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
